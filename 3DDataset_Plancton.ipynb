{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch Giff Dataset Class for loading gifs using Pytorch DataLoader.\n",
    "This Dataset resizes all frames to a specific size.\n",
    "\n",
    "Facundo Calcagno\n",
    "\"\"\"\n",
    "from __future__ import print_function, division\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image,ImageFile,ImageFilter , ImageOps, ImageDraw\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from sklearn.metrics import recall_score\n",
    "from skimage import transform\n",
    "import random\n",
    "import pickle\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss, Recall, Precision\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"No tensorboardX package is found. Please install with the command: \\npip install tensorboardX\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchy #\n",
    "We are going to work with different hierarchies to detect objects\n",
    "1st hierarchy : Living or Not Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_obj(name ):\n",
    "    with open('../obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "hier=pd.DataFrame(load_obj(\"hierarchy\"),columns=(\"level1\",\"level2\",\"level3\",\"level4\"))\n",
    "classes_transf=load_obj(\"dictionary_classes\")\n",
    "hierclasses1=hier['level1'].unique()\n",
    "hierclasses2=hier['level2'].unique()\n",
    "hierclasses3=hier['level4'].unique()\n",
    "transfpos=2\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#transform=transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plancton3DDataset(data.Dataset):\n",
    "    \"\"\"Dataset Class for loading Gif into a 3D Tensor\"\"\"\n",
    "    def __init__(self,gifList,rootDir, channels,  timeDepth, xSize, ySize, \n",
    "                 startFrame,endFrame,numFilters,filters,keys,classes_transf,transfpos,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        clipsList (string): Path to the clipsList file with labels.\n",
    "        rootDir (string): Directory with all the 3D Images.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        channels: Number of channels of frames\n",
    "        timeDepth: Number of frames to be loaded in a sample to construct the 3D Matrix\n",
    "        xSize, ySize: Dimensions of the frames\n",
    "        startFrame,endFrame: first and last frame from the original gif\n",
    "        filters: numbers of filters that you would input\n",
    "        classes_trans: Transformation from folder name to class name\n",
    "        transfpos: hierarchy to apply as output (0 is 'living' and 'not living')\n",
    "        transform: transformation to apply to the frames\n",
    "        \"\"\"\n",
    "        self.gifList = gifList\n",
    "        self.rootDir = rootDir\n",
    "        self.channels = channels\n",
    "        self.timeDepth = timeDepth\n",
    "        self.xSize = xSize\n",
    "        self.ySize = ySize\n",
    "        #self.mean = mean\n",
    "        self.transform = transform\n",
    "        self.startFrame=startFrame\n",
    "        self.endFrame=endFrame\n",
    "        self.numFilters=numFilters\n",
    "        self.keys=keys\n",
    "        #self.keys= pd.read_csv(\"../plancton_species.csv\",delimiter=\";\",header=0,names =(\"0\"))\n",
    "        self.classes =[d for d in self.keys]\n",
    "        self.classes.sort()\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "        self.filters=filters\n",
    "        self.classes_transf=classes_transf\n",
    "        self.transfpos=transfpos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gifList)\n",
    "    \n",
    "    def crop6(self,im):\n",
    "        number_of_cols=3\n",
    "        W=im.width\n",
    "        H=im.height\n",
    "        w=(W-16)/3\n",
    "        h=(H-24)/2\n",
    "        images=[]\n",
    "        w1=0\n",
    "        w2=w\n",
    "        for i in range(number_of_cols):\n",
    "            im1=im.crop((w1, 0, w2, h))\n",
    "            images.append(im1)\n",
    "            im1=im.crop((w1, h+8, w2, 2*h+8))\n",
    "            images.append(im1)\n",
    "            w1=w2+8\n",
    "            w2=w2+w+8\n",
    "        return images\n",
    "    \n",
    "    def readGif(self, gifFile):\n",
    "        # Open the gif file, crop it and return the frames in a tensor\n",
    "        image_gif=Image.open(gifFile, mode='r')\n",
    "        width, height = image_gif.size\n",
    "        w=(width-16)/3\n",
    "        h=(height-24)/2\n",
    "        #frames = torch.FloatTensor(self.numFilters,self.timeDepth,  \n",
    "        #                            self.xSize, self.ySize)\n",
    "        \n",
    "        frames=np.zeros((self.numFilters,self.timeDepth,int(h), int(w)))\n",
    "        nframes = 0\n",
    "        nframesin=0\n",
    "\n",
    "        while image_gif:\n",
    "            if self.startFrame<=nframes<=self.endFrame:\n",
    "                six_images=self.crop6(image_gif)\n",
    "                for ifilter in range(self.numFilters):\n",
    "                    realfilter=self.filters[ifilter]\n",
    "                    if self.channels == 3: pil_image = six_images[realfilter].convert(\"RGB\")\n",
    "                    if self.channels == 1: pil_image = six_images[realfilter].convert(\"L\") \n",
    "                    frame = np.asarray(pil_image).astype(np.float32)   \n",
    "                    frames[ifilter,nframes, :, :] = frame\n",
    "                nframesin+=1\n",
    "            nframes += 1\n",
    "            try:\n",
    "                image_gif.seek( nframes )\n",
    "            except EOFError:\n",
    "                break;\n",
    "            \n",
    "        image_gif.close()\n",
    "        return frames\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file,folder,typeplan=self.gifList.iloc[idx]\n",
    "        typeplan=self.classes_transf[folder][self.transfpos]\n",
    "        gifFile= os.path.join(self.rootDir, os.path.join(folder,file))\n",
    "        clip = self.readGif(gifFile)\n",
    "        if self.transform:\n",
    "            clip = self.transform(clip)\n",
    "        return clip,self.class_to_idx[typeplan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transormations ##\n",
    "   \n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the 3 3D images in a sample to a given size.\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of widht ad height (Lenght stays the same) \n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        image=sample\n",
    "    \n",
    "        c,f,h, w = image.shape\n",
    "        \n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "            \n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        #Generate a resize\n",
    "        frames=np.zeros((c,f,new_h, new_w))\n",
    "        for c_i in range(c):\n",
    "            for f_i in range(f):\n",
    "                new_image=transform.resize(image[c_i,f_i,:,:],(new_h, new_w))\n",
    "                frames [c_i,f_i,:,:]=new_image\n",
    "        \n",
    "        return frames\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the 3D image in a sample, using the same crop for all filters and frames\n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of each frame of each filter. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image= sample\n",
    "        \n",
    "        c,f,h, w = image.shape\n",
    "        new_h, new_w = self.output_size      \n",
    "        top = np.random.randint(0, abs(h - new_h))\n",
    "        left = np.random.randint(0, abs(w - new_w))\n",
    "        frames = image[:,:,top: top + new_h,left: left + new_w]\n",
    "        return frames\n",
    "    \n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize the 3 filters \n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of each frame of each filter. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, stddev):\n",
    "        self.mean = mean\n",
    "        self.stddev= stddev\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image= sample\n",
    "        \n",
    "        c,f,h, w = image.shape\n",
    "        for c_i in range(c):\n",
    "             image[c_i,:,:,:]=(image[c_i,:,:,:] - self.mean[c_i])/self.stddev[c_i]\n",
    "        return image\n",
    "    \n",
    "class RandomRotate(object):\n",
    "    \"\"\" Rotate 90/180/270 degrees all filters\"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.degrees=list([0,90,180,270])\n",
    "        \n",
    "    \n",
    "    def __call__ (self,sample):\n",
    "        c,f,h, w = sample.shape\n",
    "        choice=random.choice(self.degrees)\n",
    "        if choice==90:\n",
    "            frames=np.zeros((c,f,w, h))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.rot90(sample[c_i,f_i,:,:])\n",
    "            return frames       \n",
    "            #rotate 90 degrees\n",
    "        elif choice==180:\n",
    "            #rotate 180 degrees\n",
    "            frames=np.zeros((c,f,h, w))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.rot90(sample[c_i,f_i,:,:],2)\n",
    "            return frames\n",
    "        elif choice==270:\n",
    "            frames=np.zeros((c,f,w, h))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.rot90(sample[c_i,f_i,:,:],-1)\n",
    "            return frames\n",
    "        else:\n",
    "            return sample\n",
    "            #rotate 270 degrees\n",
    "            \n",
    "class RandomFlip(object):        \n",
    "    def __init__(self):\n",
    "        self.direction=list([\"Nothing\",\"LRDirection\",\"UDDirection\"])\n",
    "        \n",
    "    def __call__ (self,sample):\n",
    "        c,f,h, w = sample.shape\n",
    "        choice=random.choice(self.direction)\n",
    "        if choice == \"Nothing\":\n",
    "            #Do nothing\n",
    "            return sample\n",
    "        elif choice==\"LRDirection\":\n",
    "            frames=np.zeros((c,f,h, w))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.fliplr(sample[c_i,f_i,:,:])\n",
    "            return frames\n",
    "        elif choice==\"UDDirection\":\n",
    "            frames=np.zeros((c,f,h,w))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.flipud(sample[c_i,f_i,:,:])\n",
    "            return frames\n",
    "            \n",
    "        \n",
    "                \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        return torch.from_numpy(np.asarray(sample).astype(np.float32))  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to keep the top right image of all gifs and resize to a 100x100x3 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gifListFile=\"../plancton-train.csv\";rootDir=\"../taraImages/\";\n",
    "channels=1;timeDepth=16;xSize=112;ySize=112;startFrame=0;endFrame=15;numFilters=5;Filters=[0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Reading and writing a Gif ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pdataset=plancton3DDataset(gifListFile,rootDir,channels,timeDepth,xSize,ySize,startFrame,\n",
    "#                          endFrame,numFilters,Filters,hierclasses1,classes_transf,transfpos,transform=compose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../taraImages/artefact_bubble/10755960_S125--D3--R27--G100010731--A130823--L01009--animation.gif\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use train and test files created in ``Train Test text file``  to import files into the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"../logs/\"\n",
    "trainset=\"../plancton-train.csv\"\n",
    "testset=\"../plancton-test.csv\"\n",
    "trainlist=pd.read_csv(trainset,delimiter=\";\",header=1,names =(\"file\",\"folder\",\"type\"))\n",
    "testlist=pd.read_csv(testset,delimiter=\";\",header=1,names =(\"file\",\"folder\",\"type\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Mean and StdDev ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file,folder,typeplan=trainlist.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testlist1=testlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucf_collate(batch):\n",
    "    label = torch.zeros(len(batch))\n",
    "    input = torch.zeros(len(batch),5, 16, 112, 112)\n",
    "    for i in range(len(batch)):\n",
    "        input_label = batch[i]\n",
    "        label[i] = int(float(input_label[1]))\n",
    "        input_list = input_label[0]\n",
    "        for j in range(len(input_list)):\n",
    "            input[i][j] = input_list[j]\n",
    "\n",
    "    #input = input.permute(0, 2, 3, 4, 1)\n",
    "\n",
    "    return (input, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "total=84027\n",
    "BS = 15\n",
    "outputsize=len(hierclasses3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "composeT=transforms.Compose([Rescale(112),\n",
    "                                ToTensor()])\n",
    "try_batch_size=1000\n",
    "train_loader = data.DataLoader(plancton3DDataset(gifList=trainlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=5,filters=[0,1,2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=composeT), \n",
    "                               batch_size=30, shuffle=False, collate_fn=ucf_collate, **kwargs)\n",
    "val_loader = data.DataLoader(plancton3DDataset(gifList=testlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=5,filters=[0,1,2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=composeT), \n",
    "                              batch_size=60, shuffle=False, collate_fn=ucf_collate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad928dac4b4f443f9df29f72bbb7a627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_mean_channel1=0;g_mean_channel2=0;g_mean_channel3=0;g_mean_channel4=0;g_mean_channel5=0\n",
    "g_std_channel1=0;g_std_channel2=0;g_std_channel3=0;g_std_channel4=0;g_std_channel5=0\n",
    "\n",
    "nobs=0\n",
    "for batch_idx, (datax, target) in tqdm_notebook(enumerate(val_loader)):\n",
    "    datax=datax.to(device)\n",
    "    s,c,f,w,h=datax.size()\n",
    "    #Calculate mean and std per channel\n",
    "    mean_channel1=torch.mean(datax[:,0,:,:]).to(\"cpu\")\n",
    "    mean_channel2=torch.mean(datax[:,1,:,:]).to(\"cpu\")\n",
    "    mean_channel3=torch.mean(datax[:,2,:,:]).to(\"cpu\")\n",
    "    mean_channel4=torch.mean(datax[:,3,:,:]).to(\"cpu\")\n",
    "    mean_channel5=torch.mean(datax[:,4,:,:]).to(\"cpu\")\n",
    "    std_channel1=torch.std(datax[:,0,:,:]).to(\"cpu\")\n",
    "    std_channel2=torch.std(datax[:,1,:,:]).to(\"cpu\")\n",
    "    std_channel3=torch.std(datax[:,2,:,:]).to(\"cpu\")\n",
    "    std_channel4=torch.std(datax[:,3,:,:]).to(\"cpu\")\n",
    "    std_channel5=torch.std(datax[:,4,:,:]).to(\"cpu\")\n",
    "    m = nobs * 1.0\n",
    "    n = s\n",
    "    tmp = g_mean_channel1\n",
    "    g_mean_channel1 = m/(m+n)*tmp + n/(m+n)*mean_channel1\n",
    "    g_std_channel1  = np.sqrt(m/(m+n)*g_std_channel1**2 + n/(m+n)*std_channel1**2 +  m*n/(m+n)**2 * (tmp - mean_channel1)**2)\n",
    "    tmp = g_mean_channel2\n",
    "    g_mean_channel2 = m/(m+n)*tmp + n/(m+n)*mean_channel2\n",
    "    g_std_channel2  = np.sqrt(m/(m+n)*g_std_channel2**2 + n/(m+n)*std_channel2**2 +  m*n/(m+n)**2 * (tmp - mean_channel2)**2)\n",
    "    tmp = g_mean_channel3\n",
    "    g_mean_channel3 = m/(m+n)*tmp + n/(m+n)*mean_channel3\n",
    "    g_std_channel3  = np.sqrt(m/(m+n)*g_std_channel3**2 + n/(m+n)*std_channel3**2 +  m*n/(m+n)**2 * (tmp - mean_channel3)**2)    \n",
    "    tmp = g_mean_channel4\n",
    "    g_mean_channel4 = m/(m+n)*tmp + n/(m+n)*mean_channel4\n",
    "    g_std_channel4  = np.sqrt(m/(m+n)*g_std_channel4**2 + n/(m+n)*std_channel4**2 +  m*n/(m+n)**2 * (tmp - mean_channel4)**2)    \n",
    "    tmp = g_mean_channel5\n",
    "    g_mean_channel5 = m/(m+n)*tmp + n/(m+n)*mean_channel5\n",
    "    g_std_channel5  = np.sqrt(m/(m+n)*g_std_channel5**2 + n/(m+n)*std_channel5**2 +  m*n/(m+n)**2 * (tmp - mean_channel5)**2)    \n",
    "    nobs+=n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Globals: tensor(250.9021) tensor(251.1151) tensor(252.9046) tensor(251.4320) tensor(156.2538)\n",
      "std Globals: tensor(15.8342) tensor(13.6886) tensor(7.9116) tensor(11.3310) tensor(66.1270)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(\"mean Globals:\",g_mean_channel1,g_mean_channel2,g_mean_channel3,g_mean_channel4,g_mean_channel5)\n",
    "print(\"std Globals:\",g_std_channel1,g_std_channel2,g_std_channel3,g_std_channel4,g_std_channel5)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mean and std ###\n",
    "mean: (252.9242,251.4343,156.3816)\n",
    "std: (7.7102,11.3070,66.3204)\n",
    "\n",
    "### Validation man and std ###\n",
    "mean: (252.9046,251.4320,156.2538)\n",
    "std: (7.9116,11.3310,66.1270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion Code ###\n",
    "\n",
    "With the Following Code we are able to Input the full image, retreive the original Image from the gif, export a Pytorch Tensor and with that Tensor export a Gif file if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tensor=pdataset.readGif(\"../taraImages/artefact_bubble/10755960_S125--D3--R27--G100010731--A130823--L01009--animation.gif\")\n",
    "#tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data Augmentation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image ###\n",
    "<img src=\"../taraImages/Chaetoceros_Chaetoceros 1 temp/10833272_S122--D1--R27--G100010241--A130821--L02556--animation.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Shape: (5, 16, 190, 435)\n"
     ]
    }
   ],
   "source": [
    "pdataset=plancton3DDataset(gifListFile,rootDir,channels,timeDepth,xSize,ySize,startFrame,\n",
    "                          endFrame,numFilters,Filters,hierclasses1,classes_transf,transfpos)\n",
    "tensor=pdataset.readGif(\"../taraImages/Chaetoceros_Chaetoceros 1 temp/10833272_S122--D1--R27--G100010241--A130821--L02556--animation.gif\")\n",
    "print(\"Tensor Shape:\",tensor.shape)\n",
    "\n",
    "rescale=Rescale(200)\n",
    "crop=RandomCrop((120))\n",
    "rotate=RandomRotate()\n",
    "flip=RandomFlip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 190 435\n"
     ]
    }
   ],
   "source": [
    "show_gif(tensor,'../out_gif/out9.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/out9.gif\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gif(tensor,directory):\n",
    "    c,f,h,w=tensor.shape\n",
    "    print(c,f,h,w)\n",
    "    new_im=[]\n",
    "    for frame in range(f):   \n",
    "        new_im.append(Image.new('RGB', (w*5, h)))\n",
    "        x_offset = 0\n",
    "        for channel in range(c):\n",
    "            im=Image.fromarray(tensor[channel,frame,:,:])\n",
    "            new_im[frame].paste(im, (x_offset,0))\n",
    "            x_offset += im.size[0]\n",
    "        #imgplot = plt.imshow(new_im[frame])\n",
    "        new_im[0].save(directory,\n",
    "                   save_all=True,\n",
    "                   append_images=new_im[1:],\n",
    "                   duration=16,\n",
    "                   loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.ImageEnhance as ie\n",
    "import PIL.Image \n",
    "import random \n",
    "\n",
    "class RandomBrightner(object):\n",
    "    \"\"\"Brightness the 3 filters \n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of each frame of each filter. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self,var):\n",
    "        self.var = var\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image= sample\n",
    "        if random.randint(0,1)==1:\n",
    "            alpha = random.uniform(0.30, self.var)\n",
    "            print(\"alpha:\",alpha)\n",
    "            c,f,h, w = image.shape\n",
    "            image=image*alpha\n",
    "\n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 190 435\n"
     ]
    }
   ],
   "source": [
    "brightner=RandomBrightner(1)\n",
    "\n",
    "tensorBright=brightner(tensor)\n",
    "show_gif(tensorBright,'../out_gif/bright129.gif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/out9.gif\" width=\"400\" >\n",
    "\n",
    "<img src=\"../out_gif/bright129.gif\" width=\"400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 200 200\n"
     ]
    }
   ],
   "source": [
    "tensorResize=rescale(tensor)\n",
    "show_gif(tensorResize,'../out_gif/rescale106.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/rescale106.gif\" width=\"200\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Crop ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 120 120\n"
     ]
    }
   ],
   "source": [
    "tensorResize=crop(tensor)\n",
    "show_gif(tensorResize,'../out_gif/crop108.gif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/crop108.gif\" width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Flip ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 190 435\n"
     ]
    }
   ],
   "source": [
    "tensorResize=flip(tensor)\n",
    "show_gif(tensorResize,'../out_gif/flip11.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/flip11.gif\"  widht=\"300\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Rotate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 435 190\n"
     ]
    }
   ],
   "source": [
    "tensorResize=rotate(tensor)\n",
    "show_gif(tensorResize,'../out_gif/rotate2.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/rotate2.gif\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Rescale +  Crop + Rotate + Flip ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 16 112 112\n"
     ]
    }
   ],
   "source": [
    "compose=transforms.Compose([Rescale(150),\n",
    "                                RandomCrop(112),\n",
    "                                RandomRotate(),\n",
    "                                RandomFlip()])\n",
    "tensorComplete=compose(tensor)\n",
    "show_gif(tensorComplete,'../out_gif/complete3.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/complete3.gif\" widht=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genearate Data loaders ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    colmean=[252.9242,251.4343,156.3816]\n",
    "    colstddev=[7.7102,11.3070,66.3204]\n",
    "    compose=transforms.Compose([Rescale(150),\n",
    "                                RandomCrop(112),\n",
    "                                RandomRotate(),\n",
    "                                RandomFlip(),\n",
    "                                Normalize(colmean,colstddev),\n",
    "                                ToTensor()])\n",
    "    colmeanval=[252.9046,251.4320,156.2538]\n",
    "    colstddevval=[7.9116,11.3310,66.1270]\n",
    "\n",
    "    composetest=transforms.Compose([Rescale(112),\n",
    "                                Normalize(colmeanval,colstddevval),\n",
    "                                ToTensor()])\n",
    "\n",
    "    train_loader = data.DataLoader(plancton3DDataset(gifList=trainlist[:1000],\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=compose), \n",
    "                               batch_size=train_batch_size, shuffle=True, collate_fn=ucf_collate, **kwargs)\n",
    "\n",
    "    val_loader = data.DataLoader(plancton3DDataset(gifList=testlist[:100],\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=composetest), \n",
    "                              batch_size=val_batch_size, shuffle=True, collate_fn=ucf_collate, **kwargs)\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3D Model\n",
    "We need to change the first filter to allow the input of the Volume with 5 Colors ans 20 slices\n",
    "and change the last layer to 41 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "# C3D Model\n",
    "class C3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "        self.group1 = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)))\n",
    "        self.group2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.group3 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.group4 = nn.Sequential(\n",
    "            nn.Conv3d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.group5 = nn.Sequential(\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512 * 3 * 3, 2048),  \n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(2048, outputsize))           #101\n",
    "\n",
    "        self._features = nn.Sequential(\n",
    "            self.group1,\n",
    "            self.group2,\n",
    "            self.group3,\n",
    "            self.group4,\n",
    "            self.group5\n",
    "        )\n",
    "\n",
    "        self._classifier = nn.Sequential(\n",
    "            self.fc1,\n",
    "            self.fc2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self._features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self._classifier(out)\n",
    "        return self.fc3(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c3d = C3D()\n",
    "c3d.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models  import *\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "#model_alex = vgg11(num_classes=10).to(device)\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "if use_cuda:\n",
    "    c3d.cuda()\n",
    "    c3d = torch.nn.DataParallel(c3d, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "#optimizer = torch.optim.SGD(c3d.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "optimizer = torch.optim.Adam(c3d.parameters(), lr=0.001,weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[10,20,30,40], gamma=0.1)\n",
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writer(model, data_loader, log_dir):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    data_loader_iter = iter(data_loader)\n",
    "    x, y = next(data_loader_iter)\n",
    "    try:\n",
    "        writer.add_graph(model, x)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save model graph: {}\".format(e))\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLoss(y_pred,y):\n",
    "    return F.cross_entropy(y_pred, y.long())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size=15;val_batch_size=15\n",
    "log_interval=20\n",
    "model=c3d\n",
    "train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "writer = create_summary_writer(model, train_loader, log_dir)\n",
    "trainer = create_supervised_trainer(model, optimizer,myLoss, device=device)\n",
    "\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                 'crossEntropyLoss': Loss(myLoss),\n",
    "                                                'recall': Recall(), \n",
    "                                                'precision': Precision()},\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "              \"\".format(engine.state.epoch, iter, len(train_loader), engine.state.output))\n",
    "        writer.add_scalar(\"training/loss\", engine.state.output, engine.state.iteration)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_cel = metrics['crossEntropyLoss']\n",
    "    avg_recall = metrics['recall']\n",
    "    avg_precision = metrics['precision']\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f} Recall {:.2f} Precision {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_accuracy, avg_cel, avg_recall,avg_precision))\n",
    "    writer.add_scalar(\"training/avg_loss\", avg_cel, engine.state.epoch)\n",
    "    writer.add_scalar(\"training/avg_accuracy\", avg_accuracy, engine.state.epoch)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_cel = metrics['crossEntropyLoss']\n",
    "    avg_recall = metrics['recall']\n",
    "    avg_precision = metrics['precision']\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f} Recall {:.2f} Precision {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_accuracy, avg_cel, avg_recall,avg_precision))\n",
    "    writer.add_scalar(\"valdation/avg_loss\", avg_cel, engine.state.epoch)\n",
    "    writer.add_scalar(\"valdation/avg_accuracy\", avg_accuracy, engine.state.epoch)\n",
    "    writer.add_scalar(\"valdation/recall\", avg_recall, engine.state.epoch)\n",
    "    writer.add_scalar(\"valdation/precision\", avg_precision, engine.state.epoch)\n",
    "\n",
    "trainer.run(train_loader, max_epochs=epochs)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score,f1_score\n",
    "\n",
    "def train( model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    n_correct=0\n",
    "    n_total=0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)   \n",
    "        \n",
    "        loss = criterion(output, target)       \n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                \n",
    "        n_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        n_total += len(data)\n",
    "        train_acc = 100. * n_correct/n_total\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            learningrate=param_group['lr']\n",
    "        if (batch_idx + 1) % 1000 == 0:\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tTraining Accuracy:{:.0f}% \\tLearning Rate:{}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item(),train_acc,learningrate))\n",
    "        \n",
    "    print('Train Epoch: {} [({:.0f}%)]\\tLoss: {:.6f} \\tTraining Accuracy:{:.0f}% \\tLearning Rate:{}'.format(\n",
    "        epoch, 100. * batch_idx / len(train_loader), loss.item(),train_acc,learningrate))\n",
    "    return train_acc,loss.item()\n",
    "            \n",
    "def test( model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    totalpred=[]\n",
    "    totaltarget=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.long().to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target)\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            totaltarget.append(target.cpu().numpy().squeeze())\n",
    "            totalpred.append(pred.cpu().numpy().squeeze())\n",
    "             \n",
    "        y_true=np.array(totaltarget)\n",
    "        y_pred=np.array(totalpred)   \n",
    "        recall=recall_score(y_true, y_pred, average='micro') \n",
    "        precision=precision_score(y_true, y_pred, average='micro') \n",
    "        f1score=f1_score(y_true, y_pred, average='micro') \n",
    "        \n",
    "        recall_group=recall_score(y_true, y_pred,average=None) \n",
    "    test_acc=100. * correct / len(test_loader.dataset)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set:  Accuracy: {}/{} ({:.0f}%), Recall: {:.4f}, Precison: {}, F1 Score: {} \\n'.format(\n",
    "         correct, len(test_loader.dataset),test_acc,recall,precision,f1score))\n",
    "\n",
    "    return test_acc,test_loss,recall_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 3\n",
    "for epoch in range(0, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test,recall=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]\n",
    "    recall3.loc[epoch,:]=recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156_upgrades.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "for epoch in range(5, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model with Parallel*\n",
    "weights=torch.load('../models/PlanctonTara_c156_lr10.pt')\n",
    "c3d.load_state_dict(weights['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "accuracy3 = pd.DataFrame( columns=['TrainingAcc','TestingAcc'])\n",
    "loss3 = pd.DataFrame( columns=['TrainingLoss','TestingLoss'])\n",
    "recall3= pd.DataFrame( columns=['TestingRecall'])\n",
    "timing = pd.DataFrame( columns=['Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3.loc[0,:]=[50.0899,25.95]\n",
    "accuracy3.loc[1,:]=[64.9648,37.05]\n",
    "accuracy3.loc[2,:]=[69.0921,46.35]\n",
    "accuracy3.loc[3,:]=[71.6496,52.7]\n",
    "accuracy3.loc[4,:]=[73.3538,73.5207]\n",
    "accuracy3.loc[5,:]=[75.0461,74.6517]\n",
    "accuracy3.loc[6,:]=[76.4326,73.7211]\n",
    "accuracy3.loc[7,:]=[77.6929,76.3982]\n",
    "accuracy3.loc[8,:]=[79.4019,76.3982]\n",
    "accuracy3.loc[9,:]=[80.6372,74.3224]\n",
    "accuracy3.loc[10,:]=[82.0355,75.5297]\n",
    "accuracy3.loc[11,:]=[88.5834,77.949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "accuracy3.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = MultiStepLR(optimizer, milestones=[10,15,20,25], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "for epoch in range(12, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156_lr10_15.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "for epoch in range(15, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test,recall_macro=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test,loss_test,recall_group=test( c3d, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "recall_group=recall_score(y_true, y_pred,average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out156=list(zip(hierclasses3,recall_group))\n",
    "out156df=pd.DataFrame(out156)\n",
    "out156df.to_excel(\"out-156.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156_lr_16.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Living or Not Living ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda =  torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if use_cuda else {}\n",
    "total=84027\n",
    "BS = 15\n",
    "outputsize=len(hierclasses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(plancton3DDataset(gifList=trainlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses1,classes_transf=classes_transf,transfpos=0,\n",
    "                                          colmean=[253.63723244,252.92530955,157.54144258],\n",
    "                                          colstddev=[255,255,255]), \n",
    "                               batch_size=BS, shuffle=True, collate_fn=ucf_collate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(plancton3DDataset(gifList=testlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses1,classes_transf=classes_transf,transfpos=0,\n",
    "                                          colmean=[254.52891592, 253.83549938, 157.98975485],\n",
    "                                          colstddev=[255,255,255]), \n",
    "                              batch_size=1, shuffle=True, collate_fn=ucf_collate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3 = pd.DataFrame( columns=['TrainingAcc','TestingAcc'])\n",
    "loss3 = pd.DataFrame( columns=['TrainingLoss','TestingLoss'])\n",
    "recall3= pd.DataFrame( columns=['TestingRecall'])\n",
    "timing = pd.DataFrame( columns=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models  import *\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "#model_alex = vgg11(num_classes=10).to(device)\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "if use_cuda:\n",
    "    c3d.cuda()\n",
    "    c3d = torch.nn.DataParallel(c3d, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    " \n",
    "\n",
    "optimizer = torch.optim.SGD(c3d.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = MultiStepLR(optimizer, milestones=[10,15,20,28], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(5, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test,recall_group=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[end-start]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c2_ep10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "plt.figure()\n",
    "accuracy3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "plt.figure()\n",
    "loss3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for losstest in loss3.TestingLoss:\n",
    "    loss3.iloc[i,1]=losstest.item()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2=torch.load('../models/PlanctonTara_c2_ep1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3d2 = C3D()\n",
    "if use_cuda:\n",
    "    c3d2.cuda()\n",
    "    c3d2 = torch.nn.DataParallel(c3d2, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights3=weights2.copy()\n",
    "f=list(weights2['state_dict'].keys())\n",
    "for i in f:\n",
    "    out=i.replace('module.','',1)\n",
    "    weights3['state_dict'][out] = weights3['state_dict'].pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3d2.load_state_dict(weights2['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
