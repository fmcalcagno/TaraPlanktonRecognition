{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PyTorch Giff Dataset Class for loading gifs using Pytorch DataLoader.\n",
    "This Dataset resizes all frames to a specific size.\n",
    "\n",
    "Facundo Calcagno\n",
    "\"\"\"\n",
    "from __future__ import print_function, division\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image,ImageFile,ImageFilter , ImageOps, ImageDraw\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from sklearn.metrics import recall_score\n",
    "from skimage import transform\n",
    "import random\n",
    "import pickle\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss, Recall, Precision\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"No tensorboardX package is found. Please install with the command: \\npip install tensorboardX\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchy #\n",
    "We are going to work with different hierarchies to detect objects\n",
    "1st hierarchy : Living or Not Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_obj(name ):\n",
    "    with open('../obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "hier=pd.DataFrame(load_obj(\"hierarchy\"),columns=(\"living\",\"parent\",\"child\"))\n",
    "classes_transf=load_obj(\"dictionary_classes\")\n",
    "hierclasses1=hier['living'].unique()\n",
    "hierclasses2=hier['parent'].unique()\n",
    "hierclasses3=hier['child'].unique()\n",
    "transfpos=2\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#transform=transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plancton3DDataset(data.Dataset):\n",
    "    \"\"\"Dataset Class for loading Gif into a 3D Tensor\"\"\"\n",
    "    def __init__(self,gifList,rootDir, channels,  timeDepth, xSize, ySize, \n",
    "                 startFrame,endFrame,numFilters,filters,keys,classes_transf,transfpos,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        clipsList (string): Path to the clipsList file with labels.\n",
    "        rootDir (string): Directory with all the 3D Images.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        channels: Number of channels of frames\n",
    "        timeDepth: Number of frames to be loaded in a sample to construct the 3D Matrix\n",
    "        xSize, ySize: Dimensions of the frames\n",
    "        startFrame,endFrame: first and last frame from the original gif\n",
    "        filters: numbers of filters that you would input\n",
    "        classes_trans: Transformation from folder name to class name\n",
    "        transfpos: hierarchy to apply as output (0 is 'living' and 'not living')\n",
    "        transform: transformation to apply to the frames\n",
    "        \"\"\"\n",
    "        self.gifList = gifList\n",
    "        self.rootDir = rootDir\n",
    "        self.channels = channels\n",
    "        self.timeDepth = timeDepth\n",
    "        self.xSize = xSize\n",
    "        self.ySize = ySize\n",
    "        #self.mean = mean\n",
    "        self.transform = transform\n",
    "        self.startFrame=startFrame\n",
    "        self.endFrame=endFrame\n",
    "        self.numFilters=numFilters\n",
    "        self.keys=keys\n",
    "        #self.keys= pd.read_csv(\"../plancton_species.csv\",delimiter=\";\",header=0,names =(\"0\"))\n",
    "        self.classes =[d for d in self.keys]\n",
    "        self.classes.sort()\n",
    "        self.class_to_idx = {self.classes[i]: i for i in range(len(self.classes))}\n",
    "        self.filters=filters\n",
    "        self.classes_transf=classes_transf\n",
    "        self.transfpos=transfpos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gifList)\n",
    "    \n",
    "    def crop6(self,im):\n",
    "        number_of_cols=3\n",
    "        W=im.width\n",
    "        H=im.height\n",
    "        w=(W-16)/3\n",
    "        h=(H-24)/2\n",
    "        images=[]\n",
    "        w1=0\n",
    "        w2=w\n",
    "        for i in range(number_of_cols):\n",
    "            im1=im.crop((w1, 0, w2, h))\n",
    "            images.append(im1)\n",
    "            im1=im.crop((w1, h+8, w2, 2*h+8))\n",
    "            images.append(im1)\n",
    "            w1=w2+8\n",
    "            w2=w2+w+8\n",
    "        return images\n",
    "    \n",
    "    def readGif(self, gifFile):\n",
    "        # Open the gif file, crop it and return the frames in a tensor\n",
    "        image_gif=Image.open(gifFile, mode='r')\n",
    "        width, height = image_gif.size\n",
    "        w=(width-16)/3\n",
    "        h=(height-24)/2\n",
    "        #frames = torch.FloatTensor(self.numFilters,self.timeDepth,  \n",
    "        #                            self.xSize, self.ySize)\n",
    "        \n",
    "        frames=np.zeros((self.numFilters,self.timeDepth,int(h), int(w)))\n",
    "        nframes = 0\n",
    "        nframesin=0\n",
    "\n",
    "        while image_gif:\n",
    "            if self.startFrame<=nframes<=self.endFrame:\n",
    "                six_images=self.crop6(image_gif)\n",
    "                for ifilter in range(self.numFilters):\n",
    "                    realfilter=self.filters[ifilter]\n",
    "                    if self.channels == 3: pil_image = six_images[realfilter].convert(\"RGB\")\n",
    "                    if self.channels == 1: pil_image = six_images[realfilter].convert(\"L\") \n",
    "                    frame = np.asarray(pil_image).astype(np.float32)   \n",
    "                    frames[ifilter,nframes, :, :] = frame\n",
    "                nframesin+=1\n",
    "            nframes += 1\n",
    "            try:\n",
    "                image_gif.seek( nframes )\n",
    "            except EOFError:\n",
    "                break;\n",
    "            \n",
    "        image_gif.close()\n",
    "        return frames\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file,folder,typeplan=self.gifList.iloc[idx]\n",
    "        typeplan=self.classes_transf[folder][self.transfpos]\n",
    "        gifFile= os.path.join(self.rootDir, os.path.join(folder,file))\n",
    "        clip = self.readGif(gifFile)\n",
    "        if self.transform:\n",
    "            clip = self.transform(clip)\n",
    "        return clip,self.class_to_idx[typeplan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transormations ##\n",
    "   \n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the 3 3D images in a sample to a given size.\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of widht ad height (Lenght stays the same) \n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "            \n",
    "    def __call__(self, sample):\n",
    "        image=sample\n",
    "    \n",
    "        c,f,h, w = image.shape\n",
    "        \n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "            \n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        #Generate a resize\n",
    "        frames=np.zeros((c,f,new_h, new_w))\n",
    "        for c_i in range(c):\n",
    "            for f_i in range(f):\n",
    "                new_image=transform.resize(image[c_i,f_i,:,:],(new_h, new_w))\n",
    "                frames [c_i,f_i,:,:]=new_image\n",
    "        \n",
    "        return frames\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the 3D image in a sample, using the same crop for all filters and frames\n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of each frame of each filter. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image= sample\n",
    "        \n",
    "        c,f,h, w = image.shape\n",
    "        new_h, new_w = self.output_size      \n",
    "        top = np.random.randint(0, abs(h - new_h))\n",
    "        left = np.random.randint(0, abs(w - new_w))\n",
    "        frames = image[:,:,top: top + new_h,left: left + new_w]\n",
    "        return frames\n",
    "    \n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize the 3 filters \n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of each frame of each filter. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, stddev):\n",
    "        self.mean = mean\n",
    "        self.stddev= stddev\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image= sample\n",
    "        \n",
    "        c,f,h, w = image.shape\n",
    "        for c_i in range(c):\n",
    "             image[c_i,:,:,:]=(image[c_i,:,:,:] - self.mean[c_i])/self.stddev[c_i]\n",
    "        return image\n",
    "    \n",
    "class RandomRotate(object):\n",
    "    \"\"\" Rotate 90/180/270 degrees all filters\"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.degrees=list([0,90,180,270])\n",
    "        \n",
    "    \n",
    "    def __call__ (self,sample):\n",
    "        c,f,h, w = sample.shape\n",
    "        choice=random.choice(self.degrees)\n",
    "        if choice==90:\n",
    "            frames=np.zeros((c,f,w, h))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.rot90(sample[c_i,f_i,:,:])\n",
    "            return frames       \n",
    "            #rotate 90 degrees\n",
    "        elif choice==180:\n",
    "            #rotate 180 degrees\n",
    "            frames=np.zeros((c,f,h, w))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.rot90(sample[c_i,f_i,:,:],2)\n",
    "            return frames\n",
    "        elif choice==270:\n",
    "            frames=np.zeros((c,f,w, h))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.rot90(sample[c_i,f_i,:,:],-1)\n",
    "            return frames\n",
    "        else:\n",
    "            return sample\n",
    "            #rotate 270 degrees\n",
    "            \n",
    "class RandomFlip(object):        \n",
    "    def __init__(self):\n",
    "        self.direction=list([\"Nothing\",\"LRDirection\",\"UDDirection\"])\n",
    "        \n",
    "    def __call__ (self,sample):\n",
    "        c,f,h, w = sample.shape\n",
    "        choice=random.choice(self.direction)\n",
    "        if choice == \"Nothing\":\n",
    "            #Do nothing\n",
    "            return sample\n",
    "        elif choice==\"LRDirection\":\n",
    "            frames=np.zeros((c,f,h, w))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.fliplr(sample[c_i,f_i,:,:])\n",
    "            return frames\n",
    "        elif choice==\"UDDirection\":\n",
    "            frames=np.zeros((c,f,h,w))\n",
    "            for c_i in range(c):\n",
    "                for f_i in range(f):\n",
    "                    frames[c_i,f_i,:,:]= np.flipud(sample[c_i,f_i,:,:])\n",
    "            return frames\n",
    "            \n",
    "        \n",
    "                \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        return torch.from_numpy(np.asarray(sample).astype(np.float32))  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to keep the top right image of all gifs and resize to a 100x100x3 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gifListFile=\"../plancton-train.csv\";rootDir=\"../taraImages/\";\n",
    "channels=1;timeDepth=16;xSize=112;ySize=112;startFrame=0;endFrame=15;numFilters=3;Filters=[2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Reading and writing a Gif ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pdataset=plancton3DDataset(gifListFile,rootDir,channels,timeDepth,xSize,ySize,startFrame,\n",
    "#                          endFrame,numFilters,Filters,hierclasses1,classes_transf,transfpos,transform=compose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../taraImages/artefact_bubble/10755960_S125--D3--R27--G100010731--A130823--L01009--animation.gif\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use train and test files created in ``Train Test text file``  to import files into the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"../logs/\"\n",
    "trainset=\"../plancton-train.csv\"\n",
    "testset=\"../plancton-test.csv\"\n",
    "trainlist=pd.read_csv(trainset,delimiter=\";\",header=1,names =(\"file\",\"folder\",\"type\"))\n",
    "testlist=pd.read_csv(testset,delimiter=\";\",header=1,names =(\"file\",\"folder\",\"type\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean and StdDev ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist1=testlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "composeT=transforms.Compose([Rescale(112),\n",
    "                                ToTensor()])\n",
    "try_batch_size=1000\n",
    "train_loader = data.DataLoader(plancton3DDataset(gifList=trainlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=5,filters=[0,1,2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=composeT), \n",
    "                               batch_size=try_batch_size, shuffle=True, collate_fn=ucf_collate, **kwargs)\n",
    "val_loader = data.DataLoader(plancton3DDataset(gifList=testlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=5,filters=[0,1,2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=composeT), \n",
    "                              batch_size=try_batch_size, shuffle=True, collate_fn=ucf_collate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0fd78210334a23aa27fb1e55e7f49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c4433cb9b409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Calculate mean and std per channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1d95a3ec21ec>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadGif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgifFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypeplan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a1131ca35e8a>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mnew_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mframes\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    133\u001b[0m         out = warp(image, tform, output_shape=output_shape, order=order,\n\u001b[1;32m    134\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                    preserve_range=preserve_range)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    767\u001b[0m                 warped = _warp_fast(image, matrix,\n\u001b[1;32m    768\u001b[0m                                  \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                                  order=order, mode=mode, cval=cval)\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mskimage/transform/_warps_cy.pyx\u001b[0m in \u001b[0;36mskimage.transform._warps_cy._warp_fast (skimage/transform/_warps_cy.c:2637)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \"\"\"Convert the input to an array.\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_mean_channel1=0;g_mean_channel2=0;g_mean_channel3=0;g_mean_channel4=0;g_mean_channel5=0\n",
    "g_std_channel1=0;g_std_channel2=0;g_std_channel3=0;g_std_channel4=0;g_std_channel5=0\n",
    "\n",
    "nobs=0\n",
    "for batch_idx, (datax, target) in tqdm_notebook(enumerate(val_loader)):\n",
    "    s,c,f,w,h=datax.size()\n",
    "    #Calculate mean and std per channel\n",
    "    mean_channel1=torch.mean(datax[:,0,:,:])\n",
    "    mean_channel2=torch.mean(datax[:,1,:,:])\n",
    "    mean_channel3=torch.mean(datax[:,2,:,:])\n",
    "    mean_channel4=torch.mean(datax[:,3,:,:])\n",
    "    mean_channel5=torch.mean(datax[:,4,:,:])\n",
    "    std_channel1=torch.std(datax[:,0,:,:])\n",
    "    std_channel2=torch.std(datax[:,1,:,:])\n",
    "    std_channel3=torch.std(datax[:,2,:,:])\n",
    "    std_channel4=torch.std(datax[:,3,:,:])\n",
    "    std_channel5=torch.std(datax[:,4,:,:])\n",
    "    m = nobs * 1.0\n",
    "    n = s\n",
    "    tmp = g_mean_channel1\n",
    "    g_mean_channel1 = m/(m+n)*tmp + n/(m+n)*mean_channel1\n",
    "    g_std_channel1  = np.sqrt(m/(m+n)*g_std_channel1**2 + n/(m+n)*std_channel1**2 +  m*n/(m+n)**2 * (tmp - mean_channel1)**2)\n",
    "    tmp = g_mean_channel2\n",
    "    g_mean_channel2 = m/(m+n)*tmp + n/(m+n)*mean_channel2\n",
    "    g_std_channel2  = np.sqrt(m/(m+n)*g_std_channel2**2 + n/(m+n)*std_channel2**2 +  m*n/(m+n)**2 * (tmp - mean_channel2)**2)\n",
    "    tmp = g_mean_channel3\n",
    "    g_mean_channel3 = m/(m+n)*tmp + n/(m+n)*mean_channel3\n",
    "    g_std_channel3  = np.sqrt(m/(m+n)*g_std_channel3**2 + n/(m+n)*std_channel3**2 +  m*n/(m+n)**2 * (tmp - mean_channel3)**2)    \n",
    "    tmp = g_mean_channel4\n",
    "    g_mean_channel4 = m/(m+n)*tmp + n/(m+n)*mean_channel4\n",
    "    g_std_channel4  = np.sqrt(m/(m+n)*g_std_channel4**2 + n/(m+n)*std_channel4**2 +  m*n/(m+n)**2 * (tmp - mean_channel4)**2)    \n",
    "    tmp = g_mean_channel5\n",
    "    g_mean_channel5 = m/(m+n)*tmp + n/(m+n)*mean_channel5\n",
    "    g_std_channel5  = np.sqrt(m/(m+n)*g_std_channel5**2 + n/(m+n)*std_channel5**2 +  m*n/(m+n)**2 * (tmp - mean_channel5)**2)    \n",
    "    nobs+=n\n",
    "    \n",
    "print(\"mean Globals:\",g_mean_channel1,g_mean_channel2,g_mean_channel3)\n",
    "print(\"std Globals:\",g_std_channel1,g_std_channel2,g_std_channel3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mean and std ###\n",
    "mean: (252.9242,251.4343,156.3816)\n",
    "std: (7.7102,11.3070,66.3204)\n",
    "\n",
    "### Validation man and std ###\n",
    "mean: (252.9046,251.4320,156.2538)\n",
    "std: (7.9116,11.3310,66.1270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion Code ###\n",
    "\n",
    "With the Following Code we are able to Input the full image, retreive the original Image from the gif, export a Pytorch Tensor and with that Tensor export a Gif file if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tensor=pdataset.readGif(\"../taraImages/artefact_bubble/10755960_S125--D3--R27--G100010731--A130823--L01009--animation.gif\")\n",
    "#tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucf_collate(batch):\n",
    "    label = torch.zeros(len(batch))\n",
    "    input = torch.zeros(len(batch),3, 16, 112, 112)\n",
    "    for i in range(len(batch)):\n",
    "        input_label = batch[i]\n",
    "        label[i] = int(float(input_label[1]))\n",
    "        input_list = input_label[0]\n",
    "        for j in range(len(input_list)):\n",
    "            input[i][j] = input_list[j]\n",
    "\n",
    "    #input = input.permute(0, 2, 3, 4, 1)\n",
    "\n",
    "    return (input, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda =  \"\"\n",
    "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device= \"cpu\"\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "total=84027\n",
    "BS = 15\n",
    "outputsize=len(hierclasses3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data Augmentation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image ###\n",
    "<img src=\"../taraImages/Chaetoceros_Chaetoceros 1 temp/10833272_S122--D1--R27--G100010241--A130821--L02556--animation.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Shape: (3, 16, 190, 435)\n"
     ]
    }
   ],
   "source": [
    "pdataset=plancton3DDataset(gifListFile,rootDir,channels,timeDepth,xSize,ySize,startFrame,\n",
    "                          endFrame,numFilters,Filters,hierclasses1,classes_transf,transfpos)\n",
    "tensor=pdataset.readGif(\"../taraImages/Chaetoceros_Chaetoceros 1 temp/10833272_S122--D1--R27--G100010241--A130821--L02556--animation.gif\")\n",
    "print(\"Tensor Shape:\",tensor.shape)\n",
    "\n",
    "rescale=Rescale(200)\n",
    "crop=RandomCrop((100))\n",
    "rotate=RandomRotate()\n",
    "flip=RandomFlip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gif(tensor,'../out_gif/out8.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/out8.gif\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gif(tensor,directory):\n",
    "    c,f,h,w=tensor.shape\n",
    "    new_im=[]\n",
    "    for frame in range(f):   \n",
    "        new_im.append(Image.new('RGB', (w*3, h)))\n",
    "        x_offset = 0\n",
    "        for channel in range(c):\n",
    "            im=Image.fromarray(tensor[channel,frame,:,:])\n",
    "            new_im[frame].paste(im, (x_offset,0))\n",
    "            x_offset += im.size[0]\n",
    "        #imgplot = plt.imshow(new_im[frame])\n",
    "        new_im[0].save(directory,\n",
    "                   save_all=True,\n",
    "                   append_images=new_im[1:],\n",
    "                   duration=16,\n",
    "                   loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.ImageEnhance as ie\n",
    "import PIL.Image \n",
    "import random \n",
    "\n",
    "class RandomBrightner(object):\n",
    "    \"\"\"Brightness the 3 filters \n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size of each frame of each filter. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self,var):\n",
    "        self.var = var\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image= sample\n",
    "        if random.randint(0,1)==1:\n",
    "            alpha = random.uniform(0.70, self.var)\n",
    "            print(\"alpha:\",alpha)\n",
    "            c,f,h, w = image.shape\n",
    "            image=image*alpha\n",
    "\n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightner=RandomBrightner(1)\n",
    "tensor=pdataset.readGif(\"../taraImages/Chaetoceros_Chaetoceros 1 temp/10833272_S122--D1--R27--G100010241--A130821--L02556--animation.gif\")\n",
    "show_gif(tensor,'../out_gif/out126.gif')\n",
    "tensorBright=brightner(tensor)\n",
    "show_gif(tensorBright,'../out_gif/bright126.gif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/out126.gif\" width=\"400\" >\n",
    "\n",
    "<img src=\"../out_gif/bright126.gif\" width=\"400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorResize=rescale(tensor)\n",
    "show_gif(tensorResize,'../out_gif/rescale105.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/rescale105.gif\" width=\"200\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Crop ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorResize=crop(tensor)\n",
    "show_gif(tensorResize,'../out_gif/crop105.gif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/crop105.gif\" width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Flip ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDDirection\n"
     ]
    }
   ],
   "source": [
    "tensorResize=flip(tensor)\n",
    "show_gif(tensorResize,'../out_gif/flip9.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/flip9.gif\"  widht=\"300\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Rotate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorResize=rotate(tensor)\n",
    "show_gif(tensorResize,'../out_gif/rotate.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/rotate.gif\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Rescale +  Crop + Rotate + Flip ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose=transforms.Compose([Rescale(150),\n",
    "                                RandomCrop(112),\n",
    "                                RandomRotate(),\n",
    "                                RandomFlip()])\n",
    "tensorComplete=compose(tensor)\n",
    "show_gif(tensorComplete,'../out_gif/complete5.gif')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../out_gif/complete5.gif\" widht=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genearate Data loaders ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    colmean=[252.9242,251.4343,156.3816]\n",
    "    colstddev=[7.7102,11.3070,66.3204]\n",
    "    compose=transforms.Compose([Rescale(150),\n",
    "                                RandomCrop(112),\n",
    "                                RandomRotate(),\n",
    "                                RandomFlip(),\n",
    "                                Normalize(colmean,colstddev),\n",
    "                                ToTensor()])\n",
    "    colmeanval=[252.9046,251.4320,156.2538]\n",
    "    colstddevval=[7.9116,11.3310,66.1270]\n",
    "\n",
    "    composetest=transforms.Compose([Rescale(112),\n",
    "                                Normalize(colmeanval,colstddevval),\n",
    "                                ToTensor()])\n",
    "\n",
    "    train_loader = data.DataLoader(plancton3DDataset(gifList=trainlist[:1000],\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=compose), \n",
    "                               batch_size=train_batch_size, shuffle=True, collate_fn=ucf_collate, **kwargs)\n",
    "\n",
    "    val_loader = data.DataLoader(plancton3DDataset(gifList=testlist[:100],\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses3,classes_transf=classes_transf,transfpos=2,transform=composetest), \n",
    "                              batch_size=val_batch_size, shuffle=True, collate_fn=ucf_collate, **kwargs)\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3D Model\n",
    "We need to change the first filter to allow the input of the Volume with 5 Colors ans 20 slices\n",
    "and change the last layer to 41 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "# C3D Model\n",
    "class C3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "        self.group1 = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)))\n",
    "        self.group2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.group3 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.group4 = nn.Sequential(\n",
    "            nn.Conv3d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.group5 = nn.Sequential(\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512 * 3 * 3, 2048),  \n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(2048, outputsize))           #101\n",
    "\n",
    "        self._features = nn.Sequential(\n",
    "            self.group1,\n",
    "            self.group2,\n",
    "            self.group3,\n",
    "            self.group4,\n",
    "            self.group5\n",
    "        )\n",
    "\n",
    "        self._classifier = nn.Sequential(\n",
    "            self.fc1,\n",
    "            self.fc2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self._features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self._classifier(out)\n",
    "        return self.fc3(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (group1): Sequential(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (group2): Sequential(\n",
       "    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (group3): Sequential(\n",
       "    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (group4): Sequential(\n",
       "    (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (group5): Sequential(\n",
       "    (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=4608, out_features=2048, bias=True)\n",
       "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=156, bias=True)\n",
       "  )\n",
       "  (_features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (_classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=4608, out_features=2048, bias=True)\n",
       "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3d = C3D()\n",
    "c3d.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models  import *\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "#model_alex = vgg11(num_classes=10).to(device)\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "if use_cuda:\n",
    "    c3d.cuda()\n",
    "    c3d = torch.nn.DataParallel(c3d, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "#optimizer = torch.optim.SGD(c3d.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "optimizer = torch.optim.Adam(c3d.parameters(), lr=0.001,weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[10,20,30,40], gamma=0.1)\n",
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writer(model, data_loader, log_dir):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    data_loader_iter = iter(data_loader)\n",
    "    x, y = next(data_loader_iter)\n",
    "    try:\n",
    "        writer.add_graph(model, x)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save model graph: {}\".format(e))\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLoss(y_pred,y):\n",
    "    return F.cross_entropy(y_pred, y.long())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size=15;val_batch_size=15\n",
    "log_interval=20\n",
    "model=c3d\n",
    "train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "writer = create_summary_writer(model, train_loader, log_dir)\n",
    "trainer = create_supervised_trainer(model, optimizer,myLoss, device=device)\n",
    "\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                 'crossEntropyLoss': Loss(myLoss),\n",
    "                                                'recall': Recall(), \n",
    "                                                'precision': Precision()},\n",
    "                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[20/67] Loss: 0.14\n",
      "Epoch[1] Iteration[40/67] Loss: 0.11\n",
      "Epoch[1] Iteration[60/67] Loss: 0.88\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.cuda.LongTensor but found type torch.cuda.FloatTensor for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b84da2e50c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valdation/precision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"firing handlers for event %s \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b84da2e50c9d>\u001b[0m in \u001b[0;36mlog_training_results\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mavg_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"firing handlers for event %s \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36miteration_completed\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miteration_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ignite/metrics/categorical_accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.cuda.LongTensor but found type torch.cuda.FloatTensor for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "              \"\".format(engine.state.epoch, iter, len(train_loader), engine.state.output))\n",
    "        writer.add_scalar(\"training/loss\", engine.state.output, engine.state.iteration)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_cel = metrics['crossEntropyLoss']\n",
    "    avg_recall = metrics['recall']\n",
    "    avg_precision = metrics['precision']\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f} Recall {:.2f} Precision {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_accuracy, avg_cel, avg_recall,avg_precision))\n",
    "    writer.add_scalar(\"training/avg_loss\", avg_cel, engine.state.epoch)\n",
    "    writer.add_scalar(\"training/avg_accuracy\", avg_accuracy, engine.state.epoch)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_cel = metrics['crossEntropyLoss']\n",
    "    avg_recall = metrics['recall']\n",
    "    avg_precision = metrics['precision']\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f} Recall {:.2f} Precision {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_accuracy, avg_cel, avg_recall,avg_precision))\n",
    "    writer.add_scalar(\"valdation/avg_loss\", avg_cel, engine.state.epoch)\n",
    "    writer.add_scalar(\"valdation/avg_accuracy\", avg_accuracy, engine.state.epoch)\n",
    "    writer.add_scalar(\"valdation/recall\", avg_recall, engine.state.epoch)\n",
    "    writer.add_scalar(\"valdation/precision\", avg_precision, engine.state.epoch)\n",
    "\n",
    "trainer.run(train_loader, max_epochs=epochs)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score,f1_score\n",
    "\n",
    "def train( model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    n_correct=0\n",
    "    n_total=0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)   \n",
    "        \n",
    "        loss = criterion(output, target)       \n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                \n",
    "        n_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        n_total += len(data)\n",
    "        train_acc = 100. * n_correct/n_total\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            learningrate=param_group['lr']\n",
    "        if (batch_idx + 1) % 1000 == 0:\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tTraining Accuracy:{:.0f}% \\tLearning Rate:{}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item(),train_acc,learningrate))\n",
    "        \n",
    "    print('Train Epoch: {} [({:.0f}%)]\\tLoss: {:.6f} \\tTraining Accuracy:{:.0f}% \\tLearning Rate:{}'.format(\n",
    "        epoch, 100. * batch_idx / len(train_loader), loss.item(),train_acc,learningrate))\n",
    "    return train_acc,loss.item()\n",
    "            \n",
    "def test( model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    totalpred=[]\n",
    "    totaltarget=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.long().to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target)\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            totaltarget.append(target.cpu().numpy().squeeze())\n",
    "            totalpred.append(pred.cpu().numpy().squeeze())\n",
    "             \n",
    "        y_true=np.array(totaltarget)\n",
    "        y_pred=np.array(totalpred)   \n",
    "        recall=recall_score(y_true, y_pred, average='micro') \n",
    "        precision=precision_score(y_true, y_pred, average='micro') \n",
    "        f1score=f1_score(y_true, y_pred, average='micro') \n",
    "        \n",
    "        recall_group=recall_score(y_true, y_pred,average=None) \n",
    "    test_acc=100. * correct / len(test_loader.dataset)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set:  Accuracy: {}/{} ({:.0f}%), Recall: {:.4f}, Precison: {}, F1 Score: {} \\n'.format(\n",
    "         correct, len(test_loader.dataset),test_acc,recall,precision,f1score))\n",
    "\n",
    "    return test_acc,test_loss,recall_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [14985/84027 (18%)]\tLoss: 2.885078 \tTraining Accuracy:24% \tLearning Rate:0.001\n",
      "Train Epoch: 0 [29985/84027 (36%)]\tLoss: 2.803012 \tTraining Accuracy:33% \tLearning Rate:0.001\n",
      "Train Epoch: 0 [44985/84027 (54%)]\tLoss: 1.575239 \tTraining Accuracy:38% \tLearning Rate:0.001\n",
      "Train Epoch: 0 [59985/84027 (71%)]\tLoss: 1.598436 \tTraining Accuracy:42% \tLearning Rate:0.001\n",
      "Train Epoch: 0 [74985/84027 (89%)]\tLoss: 1.261168 \tTraining Accuracy:45% \tLearning Rate:0.001\n",
      "Train Epoch: 0 [(100%)]\tLoss: 0.717660 \tTraining Accuracy:46% \tLearning Rate:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 12942/20956 (62%), Recall: 0.6176, Precison: 0.6175796907806833, F1 Score: 0.6175796907806833 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b8ecd006b4d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mc3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maccuracy3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtiming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy3' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 3\n",
    "for epoch in range(0, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test,recall=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]\n",
    "    recall3.loc[epoch,:]=recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156_upgrades.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [14985/84027 (18%)]\tLoss: 0.614829 \tTraining Accuracy:76% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [29985/84027 (36%)]\tLoss: 0.297347 \tTraining Accuracy:75% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [44985/84027 (54%)]\tLoss: 0.572698 \tTraining Accuracy:75% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [59985/84027 (71%)]\tLoss: 0.713374 \tTraining Accuracy:75% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [74985/84027 (89%)]\tLoss: 0.609243 \tTraining Accuracy:75% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [67212/84027 (100%)]\tLoss: 0.462370 \tTraining Accuracy:75% \tLearning Rate:0.001\n",
      "\n",
      "Test set: , Accuracy: 15644/20956 (75%),Recall: 0.7465\n",
      "\n",
      "Train Epoch: 6 [14985/84027 (18%)]\tLoss: 0.542043 \tTraining Accuracy:77% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [29985/84027 (36%)]\tLoss: 0.717838 \tTraining Accuracy:77% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [44985/84027 (54%)]\tLoss: 0.749439 \tTraining Accuracy:77% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [59985/84027 (71%)]\tLoss: 0.271600 \tTraining Accuracy:76% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [74985/84027 (89%)]\tLoss: 1.165843 \tTraining Accuracy:76% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [67212/84027 (100%)]\tLoss: 1.264409 \tTraining Accuracy:76% \tLearning Rate:0.001\n",
      "\n",
      "Test set: , Accuracy: 15449/20956 (74%),Recall: 0.7372\n",
      "\n",
      "Train Epoch: 7 [14985/84027 (18%)]\tLoss: 0.693868 \tTraining Accuracy:78% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [29985/84027 (36%)]\tLoss: 0.617669 \tTraining Accuracy:78% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [44985/84027 (54%)]\tLoss: 0.646627 \tTraining Accuracy:78% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [59985/84027 (71%)]\tLoss: 1.080791 \tTraining Accuracy:78% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [74985/84027 (89%)]\tLoss: 0.857327 \tTraining Accuracy:78% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [67212/84027 (100%)]\tLoss: 0.353820 \tTraining Accuracy:78% \tLearning Rate:0.001\n",
      "\n",
      "Test set: , Accuracy: 16010/20956 (76%),Recall: 0.7640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "for epoch in range(5, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model with Parallel*\n",
    "weights=torch.load('../models/PlanctonTara_c156_lr10.pt')\n",
    "c3d.load_state_dict(weights['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "accuracy3 = pd.DataFrame( columns=['TrainingAcc','TestingAcc'])\n",
    "loss3 = pd.DataFrame( columns=['TrainingLoss','TestingLoss'])\n",
    "recall3= pd.DataFrame( columns=['TestingRecall'])\n",
    "timing = pd.DataFrame( columns=['Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3.loc[0,:]=[50.0899,25.95]\n",
    "accuracy3.loc[1,:]=[64.9648,37.05]\n",
    "accuracy3.loc[2,:]=[69.0921,46.35]\n",
    "accuracy3.loc[3,:]=[71.6496,52.7]\n",
    "accuracy3.loc[4,:]=[73.3538,73.5207]\n",
    "accuracy3.loc[5,:]=[75.0461,74.6517]\n",
    "accuracy3.loc[6,:]=[76.4326,73.7211]\n",
    "accuracy3.loc[7,:]=[77.6929,76.3982]\n",
    "accuracy3.loc[8,:]=[79.4019,76.3982]\n",
    "accuracy3.loc[9,:]=[80.6372,74.3224]\n",
    "accuracy3.loc[10,:]=[82.0355,75.5297]\n",
    "accuracy3.loc[11,:]=[88.5834,77.949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainingAcc</th>\n",
       "      <th>TestingAcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0899</td>\n",
       "      <td>25.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.9648</td>\n",
       "      <td>37.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.0921</td>\n",
       "      <td>46.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.6496</td>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.3538</td>\n",
       "      <td>73.5207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.0461</td>\n",
       "      <td>74.6517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.4326</td>\n",
       "      <td>73.7211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77.6929</td>\n",
       "      <td>76.3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79.4019</td>\n",
       "      <td>76.3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80.6372</td>\n",
       "      <td>74.3224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.0355</td>\n",
       "      <td>75.5297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88.5834</td>\n",
       "      <td>77.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90.7851</td>\n",
       "      <td>77.8345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>92.243</td>\n",
       "      <td>77.5577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>93.4485</td>\n",
       "      <td>77.2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>95.1658</td>\n",
       "      <td>77.4814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrainingAcc TestingAcc\n",
       "0      50.0899      25.95\n",
       "1      64.9648      37.05\n",
       "2      69.0921      46.35\n",
       "3      71.6496       52.7\n",
       "4      73.3538    73.5207\n",
       "5      75.0461    74.6517\n",
       "6      76.4326    73.7211\n",
       "7      77.6929    76.3982\n",
       "8      79.4019    76.3982\n",
       "9      80.6372    74.3224\n",
       "10     82.0355    75.5297\n",
       "11     88.5834     77.949\n",
       "12     90.7851    77.8345\n",
       "13      92.243    77.5577\n",
       "14     93.4485    77.2428\n",
       "15     95.1658    77.4814"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f99217df5f8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "accuracy3.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = MultiStepLR(optimizer, milestones=[10,15,20,25], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [14985/84027 (18%)]\tLoss: 0.385262 \tTraining Accuracy:91% \tLearning Rate:0.0001\n",
      "Train Epoch: 12 [29985/84027 (36%)]\tLoss: 0.301848 \tTraining Accuracy:91% \tLearning Rate:0.0001\n",
      "Train Epoch: 12 [44985/84027 (54%)]\tLoss: 0.292516 \tTraining Accuracy:91% \tLearning Rate:0.0001\n",
      "Train Epoch: 12 [59985/84027 (71%)]\tLoss: 0.195622 \tTraining Accuracy:91% \tLearning Rate:0.0001\n",
      "Train Epoch: 12 [74985/84027 (89%)]\tLoss: 0.057323 \tTraining Accuracy:91% \tLearning Rate:0.0001\n",
      "Train Epoch: 12 [(100%)]\tLoss: 0.120172 \tTraining Accuracy:91% \tLearning Rate:0.0001\n",
      "\n",
      "Test set:  Accuracy: 16311/20956 (78%),Recall: 0.7783\n",
      "\n",
      "Train Epoch: 13 [14985/84027 (18%)]\tLoss: 0.101033 \tTraining Accuracy:92% \tLearning Rate:0.0001\n",
      "Train Epoch: 13 [29985/84027 (36%)]\tLoss: 0.158604 \tTraining Accuracy:92% \tLearning Rate:0.0001\n",
      "Train Epoch: 13 [44985/84027 (54%)]\tLoss: 0.244513 \tTraining Accuracy:92% \tLearning Rate:0.0001\n",
      "Train Epoch: 13 [59985/84027 (71%)]\tLoss: 0.213521 \tTraining Accuracy:92% \tLearning Rate:0.0001\n",
      "Train Epoch: 13 [74985/84027 (89%)]\tLoss: 0.342395 \tTraining Accuracy:92% \tLearning Rate:0.0001\n",
      "Train Epoch: 13 [(100%)]\tLoss: 0.542894 \tTraining Accuracy:92% \tLearning Rate:0.0001\n",
      "\n",
      "Test set:  Accuracy: 16253/20956 (78%),Recall: 0.7756\n",
      "\n",
      "Train Epoch: 14 [14985/84027 (18%)]\tLoss: 0.290625 \tTraining Accuracy:94% \tLearning Rate:0.0001\n",
      "Train Epoch: 14 [29985/84027 (36%)]\tLoss: 0.659146 \tTraining Accuracy:93% \tLearning Rate:0.0001\n",
      "Train Epoch: 14 [44985/84027 (54%)]\tLoss: 0.158716 \tTraining Accuracy:93% \tLearning Rate:0.0001\n",
      "Train Epoch: 14 [59985/84027 (71%)]\tLoss: 0.054777 \tTraining Accuracy:93% \tLearning Rate:0.0001\n",
      "Train Epoch: 14 [74985/84027 (89%)]\tLoss: 0.476303 \tTraining Accuracy:93% \tLearning Rate:0.0001\n",
      "Train Epoch: 14 [(100%)]\tLoss: 0.136039 \tTraining Accuracy:93% \tLearning Rate:0.0001\n",
      "\n",
      "Test set:  Accuracy: 16187/20956 (77%),Recall: 0.7724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "for epoch in range(12, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000003e-05]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156_lr10_15.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [14985/84027 (18%)]\tLoss: 0.012203 \tTraining Accuracy:95% \tLearning Rate:1.0000000000000003e-05\n",
      "Train Epoch: 15 [29985/84027 (36%)]\tLoss: 0.353945 \tTraining Accuracy:95% \tLearning Rate:1.0000000000000003e-05\n",
      "Train Epoch: 15 [44985/84027 (54%)]\tLoss: 0.328001 \tTraining Accuracy:95% \tLearning Rate:1.0000000000000003e-05\n",
      "Train Epoch: 15 [59985/84027 (71%)]\tLoss: 0.198083 \tTraining Accuracy:95% \tLearning Rate:1.0000000000000003e-05\n",
      "Train Epoch: 15 [74985/84027 (89%)]\tLoss: 0.467076 \tTraining Accuracy:95% \tLearning Rate:1.0000000000000003e-05\n",
      "Train Epoch: 15 [(100%)]\tLoss: 0.029734 \tTraining Accuracy:95% \tLearning Rate:1.0000000000000003e-05\n",
      "\n",
      "Test set:  Accuracy: 16237/20956 (77%),Recall: 0.7748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "for epoch in range(15, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test,recall_macro=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[start-end]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 16237/20956 (77%), Recall: 0.7748, Precison: 0.7748138957816377, F1 Score: 0.7748138957816377 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgueni/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc_test,loss_test,recall_group=test( c3d, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "recall_group=recall_score(y_true, y_pred,average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "out156=list(zip(hierclasses3,recall_group))\n",
    "out156df=pd.DataFrame(out156)\n",
    "out156df.to_excel(\"out-156.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c156_lr_16.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Living or Not Living ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda =  torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 10, 'pin_memory': True} if use_cuda else {}\n",
    "total=84027\n",
    "BS = 15\n",
    "outputsize=len(hierclasses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(plancton3DDataset(gifList=trainlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses1,classes_transf=classes_transf,transfpos=0,\n",
    "                                          colmean=[253.63723244,252.92530955,157.54144258],\n",
    "                                          colstddev=[255,255,255]), \n",
    "                               batch_size=BS, shuffle=True, collate_fn=ucf_collate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(plancton3DDataset(gifList=testlist,\n",
    "                                          rootDir=\"../taraImages/\",\n",
    "                                          channels=1,timeDepth=16,xSize=112,ySize=112,\n",
    "                                          startFrame=0,endFrame=15,numFilters=3,filters=[2,3,4],\n",
    "                                          keys=hierclasses1,classes_transf=classes_transf,transfpos=0,\n",
    "                                          colmean=[254.52891592, 253.83549938, 157.98975485],\n",
    "                                          colstddev=[255,255,255]), \n",
    "                              batch_size=1, shuffle=True, collate_fn=ucf_collate, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3 = pd.DataFrame( columns=['TrainingAcc','TestingAcc'])\n",
    "loss3 = pd.DataFrame( columns=['TrainingLoss','TestingLoss'])\n",
    "recall3= pd.DataFrame( columns=['TestingRecall'])\n",
    "timing = pd.DataFrame( columns=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models  import *\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "#model_alex = vgg11(num_classes=10).to(device)\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "if use_cuda:\n",
    "    c3d.cuda()\n",
    "    c3d = torch.nn.DataParallel(c3d, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    " \n",
    "\n",
    "optimizer = torch.optim.SGD(c3d.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = MultiStepLR(optimizer, milestones=[10,15,20,28], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [14985/84027 (18%)]\tLoss: 0.475663 \tTraining Accuracy:87% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [29985/84027 (36%)]\tLoss: 0.295491 \tTraining Accuracy:87% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [44985/84027 (54%)]\tLoss: 0.160385 \tTraining Accuracy:87% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [59985/84027 (71%)]\tLoss: 0.095688 \tTraining Accuracy:87% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [74985/84027 (89%)]\tLoss: 0.231538 \tTraining Accuracy:87% \tLearning Rate:0.001\n",
      "Train Epoch: 5 [(100%)]\tLoss: 0.468735 \tTraining Accuracy:87% \tLearning Rate:0.001\n",
      "\n",
      "Test set:  Accuracy: 18297/20956 (87%), Recall: 0.8731, Precison: 0.8731150983012025, F1 Score: 0.8731150983012025 \n",
      "\n",
      "Train Epoch: 6 [14985/84027 (18%)]\tLoss: 0.215710 \tTraining Accuracy:88% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [29985/84027 (36%)]\tLoss: 0.294006 \tTraining Accuracy:88% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [44985/84027 (54%)]\tLoss: 0.239123 \tTraining Accuracy:88% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [59985/84027 (71%)]\tLoss: 0.144675 \tTraining Accuracy:88% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [74985/84027 (89%)]\tLoss: 0.643816 \tTraining Accuracy:88% \tLearning Rate:0.001\n",
      "Train Epoch: 6 [(100%)]\tLoss: 0.223441 \tTraining Accuracy:88% \tLearning Rate:0.001\n",
      "\n",
      "Test set:  Accuracy: 18182/20956 (87%), Recall: 0.8676, Precison: 0.8676274098110326, F1 Score: 0.8676274098110326 \n",
      "\n",
      "Train Epoch: 7 [14985/84027 (18%)]\tLoss: 0.217183 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [29985/84027 (36%)]\tLoss: 0.357318 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [44985/84027 (54%)]\tLoss: 0.430182 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [59985/84027 (71%)]\tLoss: 0.290769 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [74985/84027 (89%)]\tLoss: 0.510290 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "Train Epoch: 7 [(100%)]\tLoss: 0.244087 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "\n",
      "Test set:  Accuracy: 18367/20956 (88%), Recall: 0.8765, Precison: 0.8764554304256538, F1 Score: 0.8764554304256538 \n",
      "\n",
      "Train Epoch: 8 [14985/84027 (18%)]\tLoss: 0.386363 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 8 [29985/84027 (36%)]\tLoss: 0.230617 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 8 [44985/84027 (54%)]\tLoss: 0.544391 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 8 [59985/84027 (71%)]\tLoss: 0.378902 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 8 [74985/84027 (89%)]\tLoss: 0.332133 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "Train Epoch: 8 [(100%)]\tLoss: 0.231189 \tTraining Accuracy:89% \tLearning Rate:0.001\n",
      "\n",
      "Test set:  Accuracy: 18314/20956 (87%), Recall: 0.8739, Precison: 0.8739263218171407, F1 Score: 0.8739263218171407 \n",
      "\n",
      "Train Epoch: 9 [14985/84027 (18%)]\tLoss: 0.320336 \tTraining Accuracy:91% \tLearning Rate:0.001\n",
      "Train Epoch: 9 [29985/84027 (36%)]\tLoss: 0.438142 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 9 [44985/84027 (54%)]\tLoss: 0.123747 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 9 [59985/84027 (71%)]\tLoss: 0.271871 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 9 [74985/84027 (89%)]\tLoss: 0.060559 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "Train Epoch: 9 [(100%)]\tLoss: 0.297839 \tTraining Accuracy:90% \tLearning Rate:0.001\n",
      "\n",
      "Test set:  Accuracy: 18223/20956 (87%), Recall: 0.8696, Precison: 0.8695838900553541, F1 Score: 0.8695838900553541 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(5, epochs):\n",
    "    start = time.clock()\n",
    "    scheduler.step()\n",
    "    acc_train,loss_train=train( c3d, device, train_loader, optimizer,epoch)\n",
    "    acc_test,loss_test,recall_group=test( c3d, device, test_loader)\n",
    "    end = time.clock()\n",
    "    accuracy3.loc[epoch,:]=[acc_train,acc_test]\n",
    "    timing.loc[epoch,:]=[end-start]\n",
    "    loss3.loc[epoch,:]=[loss_train,loss_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  'state_dict': c3d.state_dict()\n",
    "}, '../models/PlanctonTara_c2_ep10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9924822b00>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXZ//HPRRJIQjayskMABcIqRFRAFFlU2iJaF6xal1q0daM+WvWprUt9Wmx9aqtYlSrU32MLLmjdNSBuuLAKAgEMOyELISELScg21++PM1mABCbrJDPX+/XKazIn5z65ZyDfc+Y+51y3qCrGGGP8Rydvd8AYY0zbsuA3xhg/Y8FvjDF+xoLfGGP8jAW/Mcb4GQt+Y4zxMxb8xhjjZyz4jTHGz1jwG2OMnwn0dgfqExsbq/379/d2N4wxpsNYt27dIVWN82Tddhn8/fv3Z+3atd7uhjHGdBgistfTdW2oxxhj/IwFvzHG+BkLfmOM8TPtcoy/PhUVFaSnp3P06FFvd8WvBAcH07t3b4KCgrzdFWNMC/Eo+EXkLuDngAD/UNW/ikg08ArQH9gDXKmqh+tpez3woPvpY6r6UlM6mp6eTnh4OP3790dEmrIJ00iqSm5uLunp6SQmJnq7O8aYFnLKoR4RGY4T+uOAUcAPReQ04H7gY1U9DfjY/fz4ttHAQ8BZ7vYPiUi3pnT06NGjxMTEWOi3IREhJibGPmUZ42M8GeMfCnyjqiWqWgl8BlwKXAJUH72/BMyqp+2FwDJVzXN/GlgGXNTUzlrotz17z43xPZ4M9WwG/kdEYoBSYAawFkhQ1UwAVc0Ukfh62vYC9td5nu5eZowxfk9VOVhUxs6DR9iZc4Ti8ipuPW9gq//eUwa/qm4VkcdxjtaPABuBSg+3X9/hYr2T/IrIHGAOQN++fT3cfNvIzc1lypQpAGRlZREQEEBcnHOD3OrVq+ncufMpt3HjjTdy//33M3jw4AbXeeaZZ4iKiuKaa65pcl/XrFnDuHHjWL58eU2fjTHeVV7pYl9eMTsOFrMzxwl5J+yLOVJWG6fx4V24ZdKAVv+kLY2dbF1E/oBz5H4XcL77aL8H8KmqDj5u3avd69zifv68e73FJ/sdycnJevydu1u3bmXo0KGN6mtrePjhhwkLC+Oee+45Zrmqoqp06uTdK2Tvvvtu1qxZw+DBg3nhhRdaZJvt5b03pr0rKK04JtSrv9+bV0KVqzZre0QGMzAujIFxXRkYH8bAuDAGxYcRH96lyaEvIutUNdmTdT29qideVQ+KSF/gMuAcIBG4HpjnfnyrnqYfAX+oc0J3OvCAJ7+zI9ixYwezZs1i4sSJrFq1infffZdHHnmE9evXU1paylVXXcXvfvc7ACZOnMj8+fMZPnw4sbGx3HrrrXzwwQeEhoby1ltvER8fz4MPPkhsbCxz585l4sSJTJw4kRUrVlBQUMCiRYsYP348xcXF/PSnP2XHjh0kJSWRlpbGCy+8wOjRo3G5XCxdupRPPvmEc889l/Ly8ppPI4sWLeLJJ59ERBgzZgyLFi0iKyuLW265hd27dyMiLFiwgLPOOsubb6kx7Z7LpWQUlDrB7h6icb6KySkqq1kvKEBIjO3K4O7hzBjRg4HxXRkYF8aAuDDCunj3SnpPf/tS9xh/BXCbqh4WkXnAqyLyM2AfcAWAiCQDt6rqzaqaJyK/B9a4t/OoquY1t9OPvLOF1IzC5m7mGEk9I3joR8Ma3S41NZVFixbx3HPPATBv3jyio6OprKxk8uTJXH755SQlJR3TpqCggPPOO4958+Zx9913s3DhQu6//4SLolBVVq9ezdtvv82jjz7Khx9+yNNPP0337t1ZunQpGzduZMyYMTXrf/755wwZMoQBAwYwYcIEPvzwQ2bOnMnGjRt5/PHH+eqrr4iOjiYvz/knuO2225g2bRq33347lZWVlJSUNPr1G+OrjlZUsftQ9VF77RDNrpxiSiuqataLCA5kUHwYkwfHuY/iwxgYH0afbiEEBrTPe2Q9Cn5VPbeeZbnACYPIqroWuLnO84XAwmb0sV0bOHAgZ555Zs3zxYsX8+KLL1JZWUlGRgapqaknBH9ISAgXX3wxAGPHjuWLL76od9uXXXZZzTp79uwBYOXKldx3330AjBo1imHDandWixcvZvbs2QDMnj2bxYsXM3PmTFasWMFVV11FdHQ0QM3jp59+ypIlSwAIDAwkIiKiWe+FMR3RkbJKUjMK6wzROEfv+w+XUD0SLgK9okIYGBfGWYkxDIqvHaaJ6dq5w1391mHu3K2rKUfmraVr164136elpfG3v/2N1atXExUVxbXXXlvvNfB1TwYHBARQWVn/ufIuXbqcsE5D52QqKip48803ef/993nkkUdwuVzk5+dTXFyMqjb4H7Oj/Yc1pjkqq1xszy5iw/58NuzLZ2N6PmkHj9QEfJfATgyIC2Nk70guPaOXO+DDSIztSkjnAO92vgV1yOBvrwoLCwkPDyciIoLMzEw++ugjLrqoybct1GvixIm8+uqrnHvuuWzatInU1FQAUlJSOPPMM3nvvfdq1r3mmmt4++23mTp1KldeeSV33nlnzVBPdHQ0kydP5rnnnuP222+nqqqK4uJiO+o3PkNVST9cysb02pDfdKCAoxUuALqFBjG6TxQzRvRgZO9ITosPp1dUCJ06+f7BkAV/CxozZgxJSUkMHz68Zpy9pd1xxx389Kc/ZeTIkYwZM4bhw4cTGRnJE088waWXXnrMuj/+8Y9ZtGgR77zzDr/+9a+ZNGkSgYGBjB07lhdffJH58+fz85//nOeff57AwECef/55xo0b1+J9NqYtFJRUsDE9n43789mw3wn6Q0fKAegc2InhPSO4elxfRveJ4ow+3egTHeK3n3gbfTlnW2jPl3N6W2VlJZWVlQQHB5OWlsb06dNJS0sjMLD19uH23pv2pqyyim2ZzpBNddDvOlRc8/NB8WGM6h3F6D6RjO7TjcHdw+kc2D5PtLaUFr+c07QfR44cYcqUKVRWVqKqNUfrxvgqVWVPbklNwG/Yn09qRiHlVc6QTWxYF0b3ieLHY3szuk8UI3pHEhFs1WRPxhKjg4mKimLdunXe7oYxrSb3SJkzLr+/oOaIvqC0AoCQoABG9I7khgn9Gd0nilF9ougZGey3QzZNZcFvjPGaoxVVbMko4Nt9+WxML2DD/sPszysFoJPA6QnhXDy8O6P6RDG6TxSnxYe122vjOxILfmNMmzhcXE5qZiGpGYU1jztyjtSUMugZGcyoPlFce1Y/RvWJYkSvSLp6+Q5XX2XvqjGmRblcyv7DJccEfGpmIZkFtfe0dI8IZmiPcKYmxbtPwkYRHxHsxV77Fwt+Y0yTHa2oIi37CKmZBTUBvzWzqKbiZEAnYWBcV85KjCapZwRJPSIZ2iOcmLAuXu65f7Pg90BLlGUGWLhwITNmzKB79+6AZ6WaT+XPf/4zDz30ENnZ2YSHhzd5O8acSl5xOVtPMlTTtXMAQ3tEcNmYXiT1iCCpZwSnJ4QTHOQ7d7z6Cgt+D8TExLBhwwag4bLMnli4cCFjxoypCf5FixY1u2+LFy9m7NixvPXWW1x77bXN3p4xng7VJPWMYFpSgvtIPoK+0aF+cderL7Dgb6aXXnqJZ555hvLycsaPH8/8+fNxuVzceOONbNiwAVVlzpw5JCQksGHDBq666ipCQkJYvXo1F1xwwSlLNaelpXHttdeiqlx44YU8/fTT5OfnA7B9+3aqqqp4+OGH+ctf/lIT/JWVldx7770sW7aMTp06ceutt/LLX/6SVatWMXfuXEpKSggODuaTTz4hNDTUm2+f8TIbqvFPHTP4P7gfsja17Da7j4CL5zWqyebNm3nzzTf56quvCAwMZM6cOSxZsoSBAwdy6NAhNm1y+pifn09UVBRPP/008+fPZ/To0Sdsq6FSzXfccQf33HMPV1xxBfPnzz+mTXU1zsmTJ3PjjTeSm5tLTEwMzz77LBkZGWzcuJGAgADy8vI4evQos2fPZunSpYwZM4aCgoKaInDG91VP8bc1s5BtWUVscwe8DdX4p44Z/O3E8uXLWbNmDcnJzl3SpaWl9OnThwsvvJDt27dz1113MWPGDKZPn37KbTVUqnnVqlW8//77APzkJz/hwQcfrGmzZMkSPvjgAzp16sSsWbN4/fXXueWWW1i+fDlz584lIMD5g42Ojubbb7+lb9++NfX7IyMjW+6NMO1KaXkV32cXsS3LCfftWc73h0sqataxoRr/1jGDv5FH5q1FVbnpppv4/e9/f8LPvvvuOz744AOeeuopli5dyoIFC066LU9LNVdbv349u3fvZvLkyQCUlZXx3Xffccstt9RbhvlkpZlNx+RyOdUnt2YVsi2ziO3ZzuPu3OKaMsMhQQEM7h7ORcO7M6R7BIO7hzOkezhRoZ5dkGB8k6dTL/4KZ3IVBTYBN+JMvl59GUk8sFpVZ9XTtsrdBmCfqs5sbqfbi6lTp3L55Zdz1113ERsbS25uLsXFxYSEhBAcHMwVV1xBYmIit956KwDh4eEUFRU16neMGzeON998kx//+Mc1k6aAM8zz2GOPce+99wJOsPfr148DBw4wffp0nn32Wc4999yaoZ5hw4axd+9e1q9fz5gxYygsLKRr1641nwpM+1ZQWlFz5F49VLM9q4jicmcmKBHoFx3KkO4RzBzdkyHdIxjSPdyO4k29Thn8ItILuBNIUtVSEXkVmF13Vi4RWUr9c+4ClKrqiYPaPmDEiBE89NBDTJ06FZfLRVBQEM899xwBAQH87Gc/qznKfvzxxwHn8s2bb7655uSuJ5566imuu+46Hn/8cWbMmEFkZCSqyiuvvMKKFStq1hMRZs2axZIlS7jzzjtJS0tj5MiRBAYG8otf/IJbb72VxYsX84tf/IKjR48SEhLCihUr7ORuO1NZ5WL3oWK2ZhWx3X0kvy2riAP5pTXrRIYEMaR7OFck92FI93CG9Ijg9IQwQjt3oA/wqpCzDQ6sh6BgCImG0Ojax6BQZ29mWsUpyzK7g/8bYBRQCPwHeEpVU9w/D8eZc7efqp4wEa6IHFHVsMZ0ysoy1youLiY0NBQR4eWXX+bNN99k6dKlbdoHf33vW1tOURnbspwj962ZztF82sEjlFc6VScDOwkD48IY0iPcOYLvEc7Q7hEkRHTpmMN2ebth9+ew+zPnsTin4XUDuhy7IwjpdtzzaAiNOXZZcCR08t9PsC1alllVD4jIEzjhXgqkVIe+26XAx/WFvluwiKwFKoF5qvofTzpmHGvWrGHu3Lm4XC66devWItf+m7ZVWeViZ05xzSWT1SFfPUkIQEJEFwZ3j2DioNiaoB8YF9axa8gXZdcJ+s8gf5+zPCwBBpwPiedB37PBVQkleVCaV+cxF0oO1y7L2eb+2WHQqgZ+oUBI1ImfHkKiIbTbictDY5zvg/yvVIQnQz3dgEuARCAfeE1ErlXVl92rXA28cJJN9FXVDBEZAKwQkU2qurOe3zMHmAPQt2/fRr4M33X++efX3Dxm2r+S8kq2ZhaRmlFAamYhWzKcMfnyShedcBEdWEafhFguGBJfcxQ/pHsE0V194GRraT7sWVkb9jnbnOXBkdD/XDjnDkicBHGDmz6MowpHC9w7hMPH7SyOeyzKhIOpzvOK4oa3GRQKobEQ1df56tYPovq5H/tCeA+f+yThyaDgVGC3quYAiMgbwHjgZRGJAcbhHPXXS1Uz3I+7RORT4AzghOBX1QXAAnCGehrYVsf8iNuBtccZ2tqcywXlR6CsyP1VCGWFFObnkXnwIIdycyk4fIiSosO4jhYSRin9KGV0QCnRgWVEhJQS4iomsMo9Tn84EGQgVJ0O5UOgeLAThrGnQVCId19rY5SXwL6va4M+cyOoCwJDoN85MOpqJ+h7jGq54JTqo/ooiG5Eu4qjzqeFhnYURw5CwX7Y9amzw6DO//tOQRDVx9kZHLNj6O887xrX4c5HeBL8+4CzRSQUZ6hnClA9AH8F8K6qHq2vofvTQomqlolILDAB+FNTOhocHFxzg5KFf9tQVXJzcwkO9oGPwmVHIGe7O7SLah+PFjawrDbktawI4cQdYIT7q7rSUqmEUhkSjgSH0zk0kqCu8UiXcOgS7hz1dgmHzmFQcghyvofsVNj2nhOWAIgTJHFDIO50iB1c+31wO7jvorIcDqyrDfr9q8FVAZ0CofeZMOnXTtD3TobAdnZzYFAwBPWAiB6nXreyDPL3Q/5e5+vwXmeYKn+v8+9Vcui4bYfWflqo+aRQZycR0q11XlMzeDLGv0pEXgfW44zTf4v7yByYDRxzUb2IJAO3qurNwFDgeRFxAZ1wxvhTm9LR3r17k56eTk7OSU4ImRYXHBxM7969vd2Npqssh7Uvwmd/co7u6hPU1QnlLuG4uoRTIqEcDujNoaDOZFQGsk+DyK3swhFCKJZQIiKjSYiLo2dCAom9ujOoT08iI7sR0qkJ4/GVZZC70xkWOfS9s3PK2Q67PoGq2nMAhHV3PhXEDYbY0907hMGte7TpckHWd7VBv/dr95CJQI+RcPYvasfpuzTq+o32LbALxA5yvupTdsT5dHDYvWPI3weH9zjf71sFZQXHrt8lErq5dwr17Rg6d231l3S8DjPZujGN4nJB6pvw8aPOH+WA8+HMnzsn9LqEQ3AEhYSQeshFalYJW9x1anYcLKKi6tgSBkk9IxjmrlNzWkJY25QwcFU5/c7ZDoe21+4QDn3vDDtVC46q/xNCRG9o7I5IFQ6l1Z6M3bPSGR4BZ2eTeJ5zRN9/onNy1NSvNP/ETwp1dxIVJceuX31+oVs/iB4IU37bpF/bmKt6LPiN79n9BSz7LWR8CwkjYNoj5HafWDNJ95aMQrZkFtRM8QcQF96FpB7ugO8ZwbCekfRrjzc/qULhgdqdQM42Z9goZ9uxn2iCQt2fDKo/JbgfuyVCQJ0P+vn7j73EsijTWR7ZpzboEyd5NkRiTk0Vig8dN4xUZychneCOpmWfBb/xTwe3wrKHIO0jXBG92J50F29WjueLnflszXSuNhaBxJiuDHXXp6kO+vhwHziPUXyo/k8IhQdq1+kUBDGDIDrR2Vnk7XKWh8bWhvyA85wdhJ1La3uqTX7fLfiNfynMwLXiD8jGf1HeKZTXQ6/ij3mTOFIVROeATiT378aEQbGMS4xmaI8IwvxtHtejhc4QzqHttZ8Q8nY6wwrVQR83tPFDQ6ZdadEbuIxpj1SV3ekZFK34X4bseRlxVfFS1UX8veoSekf15pqJMUwcFEtyv2hCOvvWNdiNFhwBvcc6X8ZgwW86kOzCo3y54xBfp2WS8P1ibqx8lQFSxLKASWwYfDvDho1kxYAYuvnCzVDGtCILftNuFR6tYNWuPL7ccYiVOw6x42ARMzqt4oHOr9KHLLJjx5E17VGmDTmHad7urDEdiAW/aTfKKqv4dl8+X7mDfmN6AVUuJSQogOt6pPPv+EXEF25G45Ng2nwSBk21E5DGNIEFv/Eal0vZllVUc0S/encepRVVBHQSRvaO5JfnD2Rq7GGGb32SgLQPIbwnXPJ3ZNRsn6udYkxbsuA3bWp/Xglf7TzEyh25fLXjELnFzt2pg+LDuOrMPkwYFMtZA6KJKD8En/4R3vk/p8zBlIfgrFuhs80fYExzWfCbVlVcVsln3+ewcschvtxxiL25zl2L8eFdOO/0OCYMimXCoFi6R7qvoz9aCF89Dl8/A1UVMO4WmHQvdI3x4qswxrdY8JtWkX64hP/39V4Wr95H0dFKwroEcvaAGG4Y35+Jg2IZFB92bLG9qgpY90/4dJ5TBGvYZc6t69EDvPYajPFVFvymxagqa/ceZtGXu/lwcxYiwkXDu3Pd2f1I7teNwIB6bhBSha1vw/JHnJuK+k2E6Y9CL7vm3JjWYsFvmq280sV7mzJYuHIPmw4UEBkSxJxJA/npOf3oGXWS+vJ7v3Zq6qSvcYqLXf0KnH6hXaljTCuz4DdNduhIGf9etY//+2YvOUVlDIzrymOzhnPZmF4nn/g753tY/jBsf8+Z3Wjm0zDqJ8cWDzPGtBr7SzONtjWzkEVf7uY/GzIor3Rx3ulx3HRFIucOij15NcuibOdKnfX/z6keecGDcPYvvVKP3Bh/ZsFvPFLlUlZsO8jClbv5elcuIUEBXJncmxvGJzIo/hSTcJQVwVfz4aunoaoMzrwZzvs1dI1tm84bY47hUfCLyK+Am3EmotwE3Ag8B5wHVE83c4OqnjAruIhcDzzofvqYqr7U3E6btlN0tILX1qbz0td72JtbQs/IYO6/eAizz+xDVOgpauLk7YZNr8Hqf0DxQUiaBVN+BzED26Tvxpj6nTL4RaQXcCeQpKqlIvIqzpSLAPeq6usnaRsNPAQk4+w01onI26p6uPldN61pX24J//xqD6+u3c+RskrG9uvGry8cwoXDEuq/Oqda6WHY8iZsfAX2f+MsSzwPLvg39DmzbTpvjDkpT4d6AoEQEakAQoEMD9tdCCxT1TwAEVkGXAQsbmxHTetTVb7ZlcfCL3ezfGs2ASL8YGQPbpyQyOg+UQ03rCyDtBTYuMR5rCp3Zn+64Lcw8kpnWjljTLvhyWTrB0TkCWAfUAqkqGqKiPwE+B8R+R3wMXC/qpYd17wXsL/O83T3MtOOHK2o4p2NGSz8cg9bMwvpFhrEbecP4rpz+pEQ0cDMVKqwfxV89wpsfgOO5jsTfyf/DEZdBT1G22WZxrRTngz1dAMuARKBfOA1EbkWeADIAjoDC4D7gEePb17PJuud8ktE5gBzAPr2tSPEtnCw6Cgvf7OPf32zl9zicgYnhDPvshHMOqNXwxOK5+50wv67V5zJwANDYMgPYNRsGDDZLsk0pgPw5K90KrBbVXMAROQNYLyqvuz+eZmILALuqadtOnB+nee9gU/r+yWqugBnB0JycnL7mw/Sh2w+UMDClbt557sMKqqUKUPiuWliIuMHxhxbRqFacS5secMZyjmwFhBnyr5Jv4ahP3JmeDLGdBieBP8+4GwRCcUZ6pkCrBWRHqqaKU5SzAI219P2I+AP7k8NANNxPimYNlblUpalZrFw5R5W78kjtHMA15zVj+vH9ycxtp7r6CuOwvcfOkf2aSngqoT4JJj6CIy4AiJtxM6YjsqTMf5VIvI6sB6oBL7FOTL/QETicIZzNgC3AohIMnCrqt6sqnki8ntgjXtzj1af6DVto6C0glfX7OefX+3hQH4pvbuF8OAPhnJFch8iQ4KOXdnlgn1fw3dLYMtbUFYAYd2dcsijZkPCcBu3N8YHiGr7G1VJTk7WtWvXersbHVpBaQV/SdnOa+vSKSmvYlxiNDdNSGRaUgIBx99dm/O9E/bfvQYF+yCoqzOEM/JKGHC+TXpiTAcgIutUNdmTde1MnA8qPFrBT19cxZaMQi4Z3YsbJ/RneK/IY1c6kgOblzqBn/EtSCcn5C940DlZ2+UUd+MaYzosC34fU3S0gusXriY1s5Dnrh3L1KSE2h+Wl8D2951x+x0fg1ZB9xEw/X9gxOUQ3t17HTfGtBkLfh9ypKySGxatYVN6AfN/MsYJfZcL9nzhhH3q21BeBBG9YPwdMPIqSEjydreNMW3Mgt9HlJRXctOiNWzYn8/8q4ZxUdhOWPasUyun8IAzb23SJU7Y959o4/bG+DELfh9QWlbBo/9YzBlZXzG/937i310PFSUgATBoCkx7FAbPsInKjTGABX/HpAq5O2DXp1Tt/JTKtM+Y5ypy/jVdg+GMa50brPpPhJBup9ycMca/WPB3FIUZsOsz2P0Z7P7cGb4B8gPiWFFxBv2SZzBu8iyI6OHljhpj2jsL/vaqJA/2rHSCftdnkJvmLA+JhsRJVPT7L367sRtLdnXmTz8exbgz+3i3v8aYDsOCv70oL3bumq0+qs/8DlDnZqp+42Hs9U5d+4ThlLvgl/9ax/JdB/nDpSO40kLfGNMIFvzeUlUBB9bVBv3+1eCqgE5B0GccnP8ADDgPeo2FgNrSChVVLm7/93qWbz3I72cN5ydnWSVTY0zjWPC3FZcLsjfXjtHv/QrKjwACPUbB2b9wgr7vOQ1OPl5R5eLOxd+SkprNwz9K4rqz+7XtazDG+AQL/taiCnm7asfo93wBJbnOz2JOc4qeJZ7nXHkTGn3KzVVWufjVKxv4YHMWD/5gKDdMSGzlF2CM8VUW/C2t4iikPOiUNC5wTz4W0QtOu9C5xDJxUqNLGle5lP96bSPvfpfJf88Yws3nDmiFjhtj/IUFf0v77HFY8w+nuuXEuZB4PsQMbHI54yqXcu/rG3lrQwb3XjiYOZMGtmx/jTF+x4K/JWVuhC//5txAdckzzd6cy6U88MZ3vLH+AHdPO53bJg9qgU4aY/xdJ293wGdUVcBbt0HXWJj+WLM353Ipv/nPJl5dm86dU07jzimntUAnjTHGw+AXkV+JyBYR2Swii0UkWET+JSLb3csWikhQA22rRGSD++vtlu1+O/LV05C1CWY80ewyCarK797ezOLV+7lt8kB+NdVC3xjTck4Z/CLSC7gTSFbV4UAAMBv4FzAEGAGEADc3sIlSVR3t/prZMt1uZw6lwafzYOhMSGreS1RVHnknlZe/2cct5w3gnumD658A3RhjmsjTMf5AIEREKoBQIENVU6p/KCKrgd6t0L/2z+WCt++AoGDnaL8ZVJXH3tvKP7/aw80TE7n/oiEW+saYFnfKI35VPQA8AewDMoGC40I/CLgO+LCBTQSLyFoR+UZEZrVAn9uXtS86pRYu/COEJ5x6/QaoKvM+2MaLK3dzw/j+/OYHQy30jTGtwpOhnm7AJUAi0BPoKiLX1lnl78DnqvpFA5vo654A+CfAX0Wk3usRRWSOewexNicnp1Evwmvy98Pyh2HAZBj9kyZvRlX580fbef7zXVx3dj8e+lGShb4xptV4cnJ3KrBbVXNUtQJ4AxgPICIPAXHA3Q01VtUM9+Mu4FPgjAbWW6CqyaqaHBcX16gX4RWq8O6vnMcf/a3J1+kDPLk8jb9/upOrx/XlkZnDLPSNMa3Kk+DfB5wtIqHiJNIUYKuI3AxcCFytqq76GopINxHp4v4+FpgApLZM171nKz64AAATg0lEQVRs02uwYxlM+S10a3rNnL8tT+Opj9O4Mrk3/zNrOJ06WegbY1qXJ2P8q4DXgfXAJnebBcBzQALwtftSzd8BiEiyiLzgbj4UWCsiG4FPgHmq2vGD/0gOfHAf9D4Txs1p8mae+WQHTy7/nh+P6c28y0Za6Btj2oRHV/Wo6kPAQ560VdW1uC/tVNWvcC739C0f3udU1pw5v8mTlj//2U7+/NF2Zo3uyZ8ut9A3xrQdu3O3sbZ/AJuXwqR7IX5Ikzbxwhe7+OMH2/jRqJ48ccUoAiz0jTFtyIK/MY4WwLt3Q/wwmDC3SZv455e7eey9rfxgRA+evHIUgQH2T2CMaVtWpK0xlj0ER7Jg9ssQ2LnRzf/v6z08/E4qFw5L4K+zR1voG2O8wpLHU7u/gHWL4OxfOtMhNtK/V+3jt29tYerQeJ6+egxBFvrGGC+x9PFEeQm8cyd06w+Tf9Po5q+u2c9/v7mJyYPjeOaaMXQOtLfdGOM9NtTjiU//6EyjeP070Dm0UU1fX5fOfW98x6TT43j22rF0CWzaVUDGGNNS7NDzVA6sh6/nw5jrnWkTG+E/3x7g3tc3MmFgLAuuG0twkIW+Mcb7LPhPpqrCqbwZlgDTHm1U03c2ZnD3qxs4OzGGf/w02ULfGNNu2FDPyXz5V8jeDLMXQ0iUx83e35TJ3Fc2kNw/mhdvSCaks4W+Mab9sCP+huRsh8/+BMMuhSEzPG62P6+EOxd/yxl9olh0w5mEdrZ9qzGmfbHgr4+rCt66HTp3hYv/1KimH23JotKl/OXK0XTtYqFvjGl/LJnqs+YFSF8Nlz4PYfGNapqSms2Q7uH0jWnc1T/GGNNW7Ij/ePn7YPkjMGgqjLyqUU1zj5Sxdk8e04d1b6XOGWNM81nw16UK78x1JlX54ZONnlzl420HcSlMT2r6FIzGGNPabKinro1LYOfHzqTpUX0b3TxlSza9okIY1jOiFTpnjDEtw474qx05CB/eD33OhuSfNbp5SXklX6TlMC0pwaZONMa0ax4Fv4j8SkS2iMhmEVksIsEikigiq0QkTUReEZF6y1WKyAMiskNEtovIhS3b/Rb0/r1QUQIzn4ZOjd8ffv79IcoqXUwfZsM8xpj27ZQJJyK9gDuBZFUdDgQAs4HHgSdV9TTgMHDCYbKIJLnXHQZcBPxdRNrf3Uxb34HU/8B590Hc6U3aREpqFpEhQYzrH93CnTPGmJbl6aFtIBAiIoFAKJAJXIAzFy/AS8CsetpdAixR1TJV3Q3sAMY1r8strPQwvPdfkDACJtzVpE1UVrn4eOtBpgyJtxr7xph2z5PJ1g8ATwD7cAK/AFgH5KtqpXu1dKBXPc17AfvrPG9oPURkjoisFZG1OTk5nr+C5kr5LRQfgkvmQ0BQkzaxek8eBaUVNsxjjOkQPBnq6YZz5J4I9AS6AhfXs6rW19zD9VDVBaqarKrJcXFxp+pWy9j1KXz7fzD+Dug5usmbSdmSTZfATkw6vY36bYwxzeDJuMRUYLeq5qhqBfAGMB6Icg/9APQGMuppmw70qfO8ofXaXnkxvHMXRA+E8+9v8mZUlWWp2Zx7WqzV5THGdAieBP8+4GwRCRXnOsUpQCrwCXC5e53rgbfqafs2MFtEuohIInAasLr53W4Bn/wBDu9xruIJCmnyZrZkFHIgv5TpSXa3rjGmY/BkjH8Vzknc9cAmd5sFwH3A3SKyA4gBXgQQkZki8qi77RbgVZwdxYfAbapa1Qqvo3HS18I3f4fkm6D/hGZtKiU1m04CU4Y2rqaPMcZ4i6jWO+TuVcnJybp27drW2XhlOTw/CcoK4ZffQHDz7rK96K+fExEcxKu3ntNCHTTGmMYTkXWqmuzJuv537eHKv0DOVqcWTzNDf19uCduyiuxqHmNMh+JfwX9wK3z+BIy4Ak5v/k3EKalZAEyzomzGmA7Ef4K/enKV4Ai4aF6LbLK69n6/mK4tsj1jjGkL/hP8q56HA2vhoseha2yzN1dTe9+O9o0xHYx/BH/ebljxezjtQhhx+anX90BN7X2bdMUY08H4fvCrOjdqSQD88C+NnlylISlbsukZGWy1940xHY7vB/+3L8Puz2DaIxDZu0U2WVpexcodOUwf1t1q7xtjOhzfDv6iLEj5DfSbAGNvbLHNfp6Ww9EKl43vG2M6JN8O/vfvgcoy+NFTTZpcpSEpW7KJDAnizESrvW+M6Xh8N/hT33ImWDn/AYgd1GKbraxy8fG2bKYMiSfIau8bYzog30yukjx47x7oMQrOub1FN71mz2HyS6z2vjGm4/LNOsIpD0JJLly7FAJa9iWmpGZZ7X1jTIfme0f8Oz6GDf+CiXOhx8gW3bSqkrLFau8bYzo23wr+siPw7lyIOQ0m/brFN5+aabX3jTEdn28dtq54DPL3w00fQlBwi28+ZYvV3jfGdHy+c8Rfehi+WwLjfg59z26VX5GSmk1yv2hiwrq0yvaNMaYtnPKIX0QGA6/UWTQA+B1wDjDYvSwKyFfVE2YsF5E9QBFQBVR6OlFAo4V0g198DV3CWmXz+/NK2JpZyIM/GNoq2zfGmLZyyuBX1e3AaAARCQAOAG+q6l+r1xGR/wUKTrKZyap6qJl9PbWIHq226ZTUbMBq7xtjOr7GjvFPAXaq6t7qBe4J2K8ELmjJjrU3KVuyrPa+McYnNHaMfzaw+Lhl5wLZqprWQBsFUkRknYjMaWjDIjJHRNaKyNqcnJxGdqt15RWXs8Zq7xtjfITHwS8inYGZwGvH/ehqTtwZ1DVBVccAFwO3icik+lZS1QWqmqyqyXFx7evmqI+3ZlvtfWOMz2jMEf/FwHpVza5eICKBwGUce/L3GKqa4X48CLwJjGtaV70nJdVq7xtjfEdjgr++I/upwDZVTa+vgYh0FZHw6u+B6cDmpnTUW0rLq/giLYdpSQlWe98Y4xM8Cn4RCQWmAW8c96MTxvxFpKeIvO9+mgCsFJGNwGrgPVX9sHldbls1tfdtmMcY4yM8uqpHVUuAmHqW31DPsgxghvv7XcCo5nXRu1K2ZBMRHMg4q71vjPERvnPnbiuoqb0/NMFq7xtjfIal2UnU1N63yziNMT7Egv8kUlKz6Gy1940xPsaCvwE1tfcHxdK1i28VMTXG+DcL/gZszSxyau/bFIvGGB9jwd+AlNQsRGDKUAt+Y4xvseBvQMqWbJL7dSPWau8bY3yMBX899ueVkJpZaFMsGmN8kgV/PZZZ7X1jjA+z4K9HSmoWgxPC6R9rtfeNMb7Hgv84h4vLWb07z67mMcb4LAv+43y87aBTe9/G940xPsqC/zgpW7LoERnM8F5We98Y45ss+OsoLa/i87QcplvtfWOMD7Pgr+MLq71vjPEDFvx1pKRa7X1jjO87ZfCLyGAR2VDnq1BE5orIwyJyoM7yGQ20v0hEtovIDhG5v+VfQsuorHLx8VarvW+M8X2nLDupqtuB0QAiEgAcwJk0/UbgSVV9oqG27vWfwZm2MR1YIyJvq2pqC/S9Ra3de5jDVnvfGOMHGntoOwXYqap7PVx/HLBDVXepajmwBLikkb+zTaRsybba+8YYv9DY4D9+cvXbReQ7EVkoIt3qWb8XsL/O83T3shOIyBwRWSsia3NychrZreZRVVJSs6z2vjHGL3gc/CLSGZgJvOZe9CwwEGcYKBP43/qa1bNM69u+qi5Q1WRVTY6La9uj7q2ZRaQfttr7xhj/0Jgj/ouB9aqaDaCq2apapaou4B84wzrHSwf61HneG8hoamdbi9XeN8b4k8YE/9XUGeYRkR51fnYpsLmeNmuA00Qk0f2JYTbwdlM62pqs9r4xxp94FPwiEopzZc4bdRb/SUQ2ich3wGTgV+51e4rI+wCqWgncDnwEbAVeVdUtLdj/ZrPa+8YYf+PRmUxVLQFijlt2XQPrZgAz6jx/H3i/GX1sVVZ73xjjb/z+TiWrvW+M8Td+HfzVtfftaN8Y40/8OvhXVNfet8s4jTF+xK+DPyU1i+4RwYzoFentrhhjTJvx2+AvLa/is+9zmD7Mau8bY/yL3wb/yh2HnNr7dhmnMcbP+G3wp2zJIjw4kLMGWO19Y4x/8cvgr6xysXxrNlOGxFvtfWOM3/HL1FtXXXvfplg0xvghvwz+lFSrvW+M8V9+F/zVtfcnDoolzGrvG2P8kN8F/7asIvbnldoUi8YYv+V3wZ+yJdtq7xtj/Jr/BX9qFmP7diMu3GrvG2P8k18Ff/rhErZkFFptHmOMXzvl2U0RGQy8UmfRAOB3OJOm/wgoB3YCN6pqfj3t9wBFQBVQqarJze9209TW3rfLOI0x/uuUR/yqul1VR6vqaGAsUAK8CSwDhqvqSOB74IGTbGayexteC31wxvdPTwgj0WrvG2P8WGOHeqYAO1V1r6qmuKdWBPgGZyL1dutwcTmr9+RZbR5jjN9rbPDPps6E63XcBHzQQBsFUkRknYjMaeTvazErth2kyqU2vm+M8Xse38EkIp2BmRw3pCMivwEqgX810HSCqmaISDywTES2qern9Wx/DjAHoG/fvp52y2NWe98YYxyNOeK/GFivqtnVC0TkeuCHwDWqqvU1ck++jqoexDk3MK6B9RaoarKqJsfFtWwpBau9b4wxtRoT/FdTZ5hHRC4C7gNmqmpJfQ1EpKuIhFd/D0wHNje9u01jtfeNMaaWR8EvIqHANOCNOovnA+E4wzcbROQ597o9ReR99zoJwEoR2QisBt5T1Q9brPcestr7xhhTy6MxfvcRfcxxywY1sG4GMMP9/S5gVDP72CxWe98YY47l80lotfeNMeZYPh/8y6z2vjHGHMOng9+pvZ9ttfeNMaYOnw7+7dlF7Msrsdr7xhhTh08Hv9XeN8aYE/l28FvtfWOMOYHPBv+B/FI2Hyhkmg3zGGPMMXw2+JdtyQKwyziNMeY4Phv8KanZnBZvtfeNMeZ4Phn8+SXlrNqdZyWYjTGmHj4Z/DW1960omzHGnMAngz9lS7bV3jfGmAb4XPAfrXBq709LSqBTJ6u9b4wxx/O54F+ZdojSiiob3zfGmAb4XPCnpLpr7yfGnHplY4zxQz4V/FUuZfnWg1wwJJ7OgT710owxpsWcMh1FZLB7hq3qr0IRmSsi0SKyTETS3I/dGmh/vXudNPccva1m3d7D5BWX29U8xhhzEqcMflXdrqqjVXU0MBYowZk0/X7gY1U9DfjY/fwYIhINPASchTPJ+kMN7SBaQsqWLDoHdOK8wVZ73xhjGtLY8ZApwE5V3QtcArzkXv4SMKue9S8ElqlqnqoeBpYBFzW1sydTXXt/wqAYq71vjDEn0diEnA0sdn+foKqZAKqaKSLx9azfC9hf53m6e1mLO1rh4pwBMYwfZCd1jTHmZDwOfhHpDMwEHmjE9uu7kF4b2P4cYA5A3759G/ErHCGdA3j88pGNbmeMMf6mMUM9FwPrVTXb/TxbRHoAuB8P1tMmHehT53lvIKO+javqAlVNVtXkuDgbozfGmNbSmOC/mtphHoC3geqrdK4H3qqnzUfAdBHp5j6pO929zBhjjJd4FPwiEgpMA96os3geME1E0tw/m+deN1lEXgBQ1Tzg98Aa99ej7mXGGGO8RFTrHXL3quTkZF27dq23u2GMMR2GiKxT1WRP1rXbW40xxs9Y8BtjjJ+x4DfGGD9jwW+MMX6mXZ7cFZEcYG8Tm8cCh1qwOx2ZvRfHsvfjWPZ+1PKF96Kfqnp0E1S7DP7mEJG1np7Z9nX2XhzL3o9j2ftRy9/eCxvqMcYYP2PBb4wxfsYXg3+BtzvQjth7cSx7P45l70ctv3ovfG6M3xhjzMn54hG/McaYk/CZ4BeRi0Rku4jsEJETpoH0JyLSR0Q+EZGtIrJFRO7ydp+8TUQCRORbEXnX233xNhGJEpHXRWSb+//IOd7ukzeJyK/cfyebRWSxiAR7u0+tzSeCX0QCgGdw5gxIAq4WkSTv9sqrKoH/UtWhwNnAbX7+fgDcBWz1difaib8BH6rqEGAUfvy+iEgv4E4gWVWHAwE4Mw36NJ8IfpyJ3Heo6i5VLQeW4MwJ7JdUNVNV17u/L8L5w26VKS87AhHpDfwAeMHbffE2EYkAJgEvAqhquarme7dXXhcIhIhIIBBKA5NF+RJfCf42m9u3oxGR/sAZwCrv9sSr/gr8GnB5uyPtwAAgB1jkHvp6QUS6ertT3qKqB4AngH1AJlCgqine7VXr85Xg93huX38iImHAUmCuqhZ6uz/eICI/BA6q6jpv96WdCATGAM+q6hlAMeC358TcMwNeAiQCPYGuInKtd3vV+nwl+D2e29dfiEgQTuj/S1XfONX6PmwCMFNE9uAMAV4gIi97t0telQ6kq2r1J8DXcXYE/moqsFtVc1S1AmeWwfFe7lOr85XgXwOcJiKJItIZ5+TM217uk9eIiOCM4W5V1b94uz/epKoPqGpvVe2P8/9ihar6/BFdQ1Q1C9gvIoPdi6YAqV7skrftA84WkVD3380U/OBkd6C3O9ASVLVSRG7Hmcg9AFioqlu83C1vmgBcB2wSkQ3uZf+tqu97sU+m/bgD+Jf7IGkXcKOX++M1qrpKRF4H1uNcDfctfnAXr925a4wxfsZXhnqMMcZ4yILfGGP8jAW/Mcb4GQt+Y4zxMxb8xhjjZyz4jTHGz1jwG2OMn7HgN8YYP/P/Af9HLKdYL+b9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Accuracy\n",
    "plt.figure()\n",
    "accuracy3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f99242b9fd0>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Loss\n",
    "plt.figure()\n",
    "loss3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for losstest in loss3.TestingLoss:\n",
    "    loss3.iloc[i,1]=losstest.item()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrainingLoss</th>\n",
       "      <th>TestingLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543588</td>\n",
       "      <td>tensor(1.00000e-06 *\\n       6.4184, device='c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TrainingLoss                                        TestingLoss\n",
       "0     0.543588  tensor(1.00000e-06 *\\n       6.4184, device='c..."
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2=torch.load('../models/PlanctonTara_c2_ep1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3d2 = C3D()\n",
    "if use_cuda:\n",
    "    c3d2.cuda()\n",
    "    c3d2 = torch.nn.DataParallel(c3d2, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights3=weights2.copy()\n",
    "f=list(weights2['state_dict'].keys())\n",
    "for i in f:\n",
    "    out=i.replace('module.','',1)\n",
    "    weights3['state_dict'][out] = weights3['state_dict'].pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3d2.load_state_dict(weights2['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
